{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Load_Data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMpKkdqAruNEi2OxXFnts6j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seenu-g/school_of_ai/blob/master/chap15/Load_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTWKsLsv1H2P",
        "colab_type": "code",
        "outputId": "e41fdc50-7374-471d-ef83-5a0955fc1773",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-XPduWg1hyZ",
        "colab_type": "code",
        "outputId": "ee61dca6-bb60-4837-e22a-1e2d099068a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd '/content/gdrive/My Drive/school_of_ai/chap15/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/school_of_ai/chap15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5KLFztYPmrt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, random_split\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import notebook"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8Mn0t0n8R-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RawDataSet(Dataset):\n",
        "    def __init__(self,url):\n",
        "        self.fg = []\n",
        "        self.mask = []\n",
        "        self.url = url\n",
        "        self.bg = []\n",
        "        \n",
        "        for file_name in os.listdir(url+'Background/'):\n",
        "            bg = Image.open(url+'Background/'+ file_name)\n",
        "            bg_npimg = np.asarray(bg)\n",
        "            \n",
        "            if(len(bg_npimg.shape) ==2):  \n",
        "                bg_npimg = np.repeat(bg_npimg[:, :, np.newaxis], 3, axis=2)\n",
        "            self.bg.append(bg_npimg)  \n",
        "\n",
        "        for file_name in os.listdir(url+'Foreground/'):\n",
        "            fg = Image.open(url+'Foreground/'+ file_name)\n",
        "            fg_npimg = np.asarray(fg)\n",
        "            \n",
        "            if(len(fg_npimg.shape) ==2):  \n",
        "                fg_npimg = np.repeat(fg_npimg[:, :, np.newaxis], 3, axis=2)\n",
        "            self.fg.append(fg_npimg)\n",
        "\n",
        "        for file_name in os.listdir(url+'Fg-Mask/'):\n",
        "            mask = Image.open(url+'Fg-Mask/'+ file_name)\n",
        "            mask_npimg = np.asarray(mask)\n",
        "            \n",
        "            if(len(fg_npimg.shape) ==2):  \n",
        "               mask_npimg = np.repeat(mask_npimg[:, :, np.newaxis], 3, axis=2)\n",
        "            self.mask.append(mask_npimg)   \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.fg)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        bg = self.bg[idx]\n",
        "        fg = self.fg[idx]\n",
        "        mask = self.mask[idx]\n",
        "        return bg,fg,mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Pk9dLTk_nGZ",
        "colab_type": "code",
        "outputId": "f2bd5176-e0c6-425a-d135-f3a057e04a41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "  raw_folder = '/content/gdrive/My Drive/school_of_ai/archive/'\n",
        "  raw_dataset = RawDataSet(raw_folder)\n",
        "  print(len(raw_dataset))\n",
        "  raw_dataloaders = torch.utils.data.DataLoader(raw_dataset)\n",
        "  raw_dataiter = iter(raw_dataloaders)\n",
        "  bg_images,fg_images,mask_images = raw_dataiter.next()\n",
        "  bg_images = bg_images.numpy()\n",
        "  fg_images = fg_images.numpy()\n",
        "  mask_images = mask_images.numpy()\n",
        "  print(bg_images.shape)\n",
        "  print(fg_images.shape)\n",
        "  print(mask_images.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n",
            "(1, 224, 224, 3)\n",
            "(1, 90, 33, 4)\n",
            "(1, 120, 45, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcPOJrYy3oTP",
        "colab_type": "code",
        "outputId": "ba21abcd-af4f-4a37-b678-afa68cbda58d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import zipfile\n",
        "import os.path\n",
        "for i in range(1):\n",
        "  if(os.path.isfile(f'/content/gdrive/My Drive/school_of_ai/archive/data_part{str(i+1)}.zip')):\n",
        "    print(f'Extract from data_part{str(i+1)}.zip to folder data_{str(i+1)}')\n",
        "    archive = zipfile.ZipFile(f'/content/gdrive/My Drive/school_of_ai/archive/data_part{str(i+1)}.zip')\n",
        "    for file in archive.namelist():\n",
        "        archive.extract(file, '/content/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extract from data_part1.zip to folder data_1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kE57ug-KPxhF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_images(url, folder) :\n",
        "  images =[]\n",
        "  if(os.path.exists(url+folder+'/')==True) :\n",
        "       print(\"Loading \"+ url+ folder+'/')\n",
        "       for file_name in os.listdir(url+folder+'/'):\n",
        "            img = Image.open(url+folder+'/'+ file_name)\n",
        "            npimg = np.asarray(img)\n",
        "                \n",
        "            if(len(npimg.shape) ==2):  \n",
        "                npimg = np.repeat(npimg[:, :, np.newaxis], 3, axis=2)\n",
        "            images.append(npimg)\n",
        "  else:\n",
        "       print(\"Path does not exisit\",url+folder+'/')\n",
        "  return images; \n",
        "\n",
        "class InputDataSet(Dataset):\n",
        "    def __init__(self,url, folder=\"all\"):\n",
        "        self.fg_bg = []\n",
        "        self.fg_bg_mask = []\n",
        "        self.depth = []\n",
        "        self.url = url\n",
        "        self.folder = folder\n",
        "        print(\"init\")\n",
        "        if folder ==\"all\" :\n",
        "           self.fg_bg = get_images(url,'Fg-Bg') \n",
        "           self.fg_bg_mask = get_images(url,'Fg-Bg-Mask') \n",
        "           self.depth = get_images(url,'Fg-Bg') \n",
        "        elif (folder !=\"all\" and folder=='Fg-Bg') :\n",
        "           self.fg_bg = get_images(url,'Fg-Bg') \n",
        "        elif (folder !=\"all\" and folder=='Fg-Bg-Mask') :\n",
        "           self.fg_bg_mask = get_images(url,'Fg-Bg-Mask') \n",
        "        elif (folder !=\"all\" and folder=='Depth') :\n",
        "           self.depth = get_images(url,'Depth') \n",
        "        else :\n",
        "           print(\"Path does not exisit\",url+folder+'/')\n",
        "    def __len__(self):\n",
        "        if(self.folder==\"all\"):\n",
        "          return len(self.fg_bg)\n",
        "        elif (self.folder=='Fg-Bg') :\n",
        "           return len(self.fg_bg)\n",
        "        elif (self.folder=='Fg-Bg-Mask') :\n",
        "           return len(self.fg_bg_mask) \n",
        "        elif (self.folder=='Depth') :\n",
        "           return len(self.depth) \n",
        "        else :\n",
        "           return -1\n",
        "    def __getitem__(self, idx):\n",
        "        if(self.folder==\"all\") :\n",
        "          fg_bg = self.fg_bg[idx]\n",
        "          fg_bg_mask = self.fg_bg_mask[idx]\n",
        "          depth = self.depth[idx]\n",
        "          return fg_bg,fg_bg_mask,depth\n",
        "        elif (self.folder=='Fg-Bg') :\n",
        "           fg_bg = self.fg_bg[idx]\n",
        "           return fg_bg\n",
        "        elif (self.folder=='Fg-Bg-Mask') :\n",
        "           fg_bg_mask = self.fg_bg_mask[idx]\n",
        "           return fg_bg_mask\n",
        "        elif (self.folder=='Depth') :\n",
        "           depth = self.depth[idx]\n",
        "           return depth\n",
        "        else :\n",
        "           return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQpsTQUOSEwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, random_split\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import torchvision.transforms as transforms\n",
        "class DatasetFromSubset(Dataset):\n",
        "    def __init__(self, subset, transform=None):\n",
        "        self.subset = subset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x, y = self.subset[index]\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.subset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05Q9K-WkRuQg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "527c1275-0e7d-4f1f-a371-d1dc4ffa2cc8"
      },
      "source": [
        "from torch.utils.data import Dataset, random_split\n",
        "import numpy as np\n",
        "url = '/content/data_1/'\n",
        "input_dataset = InputDataSet(url,'Fg-Bg')\n",
        "train_split = 70\n",
        "train_len = len(input_dataset)*train_split//100\n",
        "test_len = len(input_dataset) - train_len \n",
        "train_set, val_set = random_split(input_dataset, [train_len, test_len])\n",
        "print(len(train_set))\n",
        "print(len(val_set))\n",
        "train_dataset = DatasetFromSubset(train_set, transform=None)\n",
        "test_dataset = DatasetFromSubset(val_set, transform=None)\n",
        "print(len(train_dataset))\n",
        "print(len(test_dataset))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "init\n",
            "Loading /content/data_1/Fg-Bg/\n",
            "56000\n",
            "24000\n",
            "56000\n",
            "24000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCnS9NZFSnj5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca48406b-0baf-4458-8cf2-0d8cc1c1b1bb"
      },
      "source": [
        "batch_size=256\n",
        "num_workers=4\n",
        "pin_memory=True\n",
        "SEED = 1\n",
        "cuda = torch.cuda.is_available()\n",
        "print(cuda)\n",
        "torch.manual_seed(SEED)\n",
        "if cuda:\n",
        "\t\t\ttorch.cuda.manual_seed(SEED)\n",
        "dataloader_args = dict(shuffle=True, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory) if cuda else dict(shuffle=True, batch_size=64)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_dataset, **dataloader_args)\n",
        "testloader = torch.utils.data.DataLoader(test_dataset, **dataloader_args)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B48QK4f_YYd3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4fa2dc2d-5135-44d2-9b0f-a95e51e16bbd"
      },
      "source": [
        "print(trainloader.batch_size)\n",
        "print(testloader.batch_size)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "64\n",
            "64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rty0_tH5ZB4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1,dropout=0.0):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "        self.dropout = dropout\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.dropout(out, p=self.dropout)\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out = F.dropout(out, p=self.dropout)\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        out = F.dropout(out, p=self.dropout)\n",
        "        return out\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10, dropout=0.0):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride, dropout=self.dropout))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.dropout(out, p=self.dropout)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.adaptive_avg_pool2d(out, 1)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "def ResNet18(dropout=0, num_classes = 10):\n",
        "    return ResNet(BasicBlock, [2,2,2,2],num_classes = num_classes , dropout=dropout)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXGGcSt-PguY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5a787de2-085c-42d1-fb64-43cc03bcba04"
      },
      "source": [
        "!pip install torchsummary\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "model = ResNet18(num_classes=200).to(device)\n",
        "summary(model, input_size=(3, 64, 64))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 64, 64]           1,728\n",
            "       BatchNorm2d-2           [-1, 64, 64, 64]             128\n",
            "            Conv2d-3           [-1, 64, 64, 64]          36,864\n",
            "       BatchNorm2d-4           [-1, 64, 64, 64]             128\n",
            "            Conv2d-5           [-1, 64, 64, 64]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 64, 64]             128\n",
            "        BasicBlock-7           [-1, 64, 64, 64]               0\n",
            "            Conv2d-8           [-1, 64, 64, 64]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 64, 64]             128\n",
            "           Conv2d-10           [-1, 64, 64, 64]          36,864\n",
            "      BatchNorm2d-11           [-1, 64, 64, 64]             128\n",
            "       BasicBlock-12           [-1, 64, 64, 64]               0\n",
            "           Conv2d-13          [-1, 128, 32, 32]          73,728\n",
            "      BatchNorm2d-14          [-1, 128, 32, 32]             256\n",
            "           Conv2d-15          [-1, 128, 32, 32]         147,456\n",
            "      BatchNorm2d-16          [-1, 128, 32, 32]             256\n",
            "           Conv2d-17          [-1, 128, 32, 32]           8,192\n",
            "      BatchNorm2d-18          [-1, 128, 32, 32]             256\n",
            "       BasicBlock-19          [-1, 128, 32, 32]               0\n",
            "           Conv2d-20          [-1, 128, 32, 32]         147,456\n",
            "      BatchNorm2d-21          [-1, 128, 32, 32]             256\n",
            "           Conv2d-22          [-1, 128, 32, 32]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 32, 32]             256\n",
            "       BasicBlock-24          [-1, 128, 32, 32]               0\n",
            "           Conv2d-25          [-1, 256, 16, 16]         294,912\n",
            "      BatchNorm2d-26          [-1, 256, 16, 16]             512\n",
            "           Conv2d-27          [-1, 256, 16, 16]         589,824\n",
            "      BatchNorm2d-28          [-1, 256, 16, 16]             512\n",
            "           Conv2d-29          [-1, 256, 16, 16]          32,768\n",
            "      BatchNorm2d-30          [-1, 256, 16, 16]             512\n",
            "       BasicBlock-31          [-1, 256, 16, 16]               0\n",
            "           Conv2d-32          [-1, 256, 16, 16]         589,824\n",
            "      BatchNorm2d-33          [-1, 256, 16, 16]             512\n",
            "           Conv2d-34          [-1, 256, 16, 16]         589,824\n",
            "      BatchNorm2d-35          [-1, 256, 16, 16]             512\n",
            "       BasicBlock-36          [-1, 256, 16, 16]               0\n",
            "           Conv2d-37            [-1, 512, 8, 8]       1,179,648\n",
            "      BatchNorm2d-38            [-1, 512, 8, 8]           1,024\n",
            "           Conv2d-39            [-1, 512, 8, 8]       2,359,296\n",
            "      BatchNorm2d-40            [-1, 512, 8, 8]           1,024\n",
            "           Conv2d-41            [-1, 512, 8, 8]         131,072\n",
            "      BatchNorm2d-42            [-1, 512, 8, 8]           1,024\n",
            "       BasicBlock-43            [-1, 512, 8, 8]               0\n",
            "           Conv2d-44            [-1, 512, 8, 8]       2,359,296\n",
            "      BatchNorm2d-45            [-1, 512, 8, 8]           1,024\n",
            "           Conv2d-46            [-1, 512, 8, 8]       2,359,296\n",
            "      BatchNorm2d-47            [-1, 512, 8, 8]           1,024\n",
            "       BasicBlock-48            [-1, 512, 8, 8]               0\n",
            "           Linear-49                  [-1, 200]         102,600\n",
            "================================================================\n",
            "Total params: 11,271,432\n",
            "Trainable params: 11,271,432\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 45.00\n",
            "Params size (MB): 43.00\n",
            "Estimated Total Size (MB): 88.05\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FaM-b4wZb4l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import OneCycleLR,StepLR\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01,momentum=0.9,weight_decay = 0.0001,nesterov = True ) \n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scheduler = OneCycleLR(optimizer, max_lr = 0.2, total_steps=None, epochs=30, steps_per_epoch=1, pct_start=1/3, anneal_strategy='linear', cycle_momentum=True, base_momentum=0.85, max_momentum=0.95, div_factor=10.0,final_div_factor =10)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}