{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA4S5F2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seenu-g/school_of_ai/blob/master/chap6/setup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kH16rnZ7wt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky3f_Odl-7um",
        "colab_type": "text"
      },
      "source": [
        "## Data Transformations\n",
        "\n",
        "We first start with defining our data transformations. We need to think what our data is and how can we augment it to correct represent images which it might not see otherwise. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtssFUKb-jqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train Phase transformations\n",
        "train_transforms = transforms.Compose([\n",
        "                                      #  transforms.Resize((28, 28)),\n",
        "                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
        "                                       #transforms.RandomRotation((-7.0, 7.0), fill=(1,)),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.1307,), (0.3081,)) # The mean and std have to be sequences (e.g., tuples), therefore you should add a comma after the values. \n",
        "                                       # Note the difference between (0.1307) and (0.1307,)\n",
        "                                       ])\n",
        "\n",
        "# Test Phase transformations\n",
        "test_transforms = transforms.Compose([\n",
        "                                      #  transforms.Resize((28, 28)),\n",
        "                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                                       ])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQciFYo2B1mO",
        "colab_type": "text"
      },
      "source": [
        "# Dataset and Creating Train/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4A84rlfDA23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = datasets.MNIST('./data', train=True, download=True, transform=train_transforms)\n",
        "test = datasets.MNIST('./data', train=False, download=True, transform=test_transforms)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgldp_3-Dn0c",
        "colab_type": "text"
      },
      "source": [
        "# Dataloader Arguments & Test/Train Dataloaders\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8OLDR79DrHG",
        "colab_type": "code",
        "outputId": "99db2223-66d6-49df-da91-5295ce6691df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "SEED = 1\n",
        "\n",
        "# CUDA?\n",
        "cuda = torch.cuda.is_available()\n",
        "print(\"CUDA Available?\", cuda)\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "# dataloader arguments - something you'll fetch these from cmdprmt\n",
        "dataloader_args = dict(shuffle=True, batch_size=128, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n",
        "print(dataloader_args)\n",
        "# train dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n",
        "# test dataloader\n",
        "test_loader = torch.utils.data.DataLoader(test, **dataloader_args)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA Available? True\n",
            "{'shuffle': True, 'batch_size': 128, 'num_workers': 4, 'pin_memory': True}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-QPKCA2MaGM",
        "colab_type": "text"
      },
      "source": [
        "**Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FXQlB9kH1ov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dropout_value = 0.03\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.conv_layer1 = nn.Sequential(                      \n",
        "            nn.Conv2d(in_channels=1, out_channels=12, kernel_size=(3, 3), padding=0, bias=True),#Op_size = 26, RF = 3\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(num_features=12),\n",
        "            #nn.Dropout2d(dropout_value)\n",
        "        )\n",
        "        self.conv_layer2 = nn.Sequential(  \n",
        "            nn.Conv2d(in_channels=12, out_channels=12, kernel_size=(3, 3), padding=0, bias=True),#Op_size = 24, RF = 5\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(num_features=12),\n",
        "            #nn.Dropout2d(dropout_value)\n",
        "        )\n",
        "        self.maxpool_layer1 = nn.MaxPool2d(kernel_size=(2,2)) #Op_size = 12, RF = 6\n",
        "        self.conv_layer3 = nn.Sequential(  \n",
        "            nn.Conv2d(in_channels=12, out_channels=14, kernel_size=(3, 3), padding=0, bias=True), #Op_size = 10, RF = 10   \n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(num_features=14),\n",
        "            #nn.Dropout2d(dropout_value)\n",
        "        )\n",
        "        self.conv_layer4 = nn.Sequential(  \n",
        "            nn.Conv2d(in_channels=14, out_channels=16, kernel_size=(3, 3), padding=0, bias=True), #Op_size = 8, RF = 14\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(num_features=16),\n",
        "            #nn.Dropout2d(dropout_value) \n",
        "        )\n",
        "        self.conv_layer5 = nn.Sequential(  \n",
        "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=1, bias=True),#Op_size = 6, RF = 18 \n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(num_features=16),\n",
        "            #nn.Dropout(dropout_value)\n",
        "        )\n",
        "        self.conv_layer6 = nn.Sequential(  \n",
        "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=0, bias=True),#Op_size = 6, RF = 22 \n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(num_features=16),\n",
        "            #nn.Dropout(dropout_value)\n",
        "        )            \n",
        "        self.avgpool_layer1 = nn.AvgPool2d(kernel_size=6)\n",
        "\n",
        "        self.conv_layer7 = nn.Sequential(  \n",
        "            nn.Conv2d(in_channels=16, out_channels=10, kernel_size=(1, 1), padding=0, bias=True)#Op_size = 1, RF = 28\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layer1(x)\n",
        "        x = self.conv_layer2(x)\n",
        "        x =  self.maxpool_layer1(x)\n",
        "        x = self.conv_layer3(x)\n",
        "        x = self.conv_layer4(x)\n",
        "        x = self.conv_layer5(x)\n",
        "        x = self.conv_layer6(x)\n",
        "        x = self.avgpool_layer1(x)\n",
        "        x = self.conv_layer7(x)\n",
        "\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x, dim=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3-vp8X9LCWo",
        "colab_type": "text"
      },
      "source": [
        "*italicized text*# Model Params\n",
        "Can't emphasize on how important viewing Model Summary is. \n",
        "Unfortunately, there is no in-built model visualizer, so we have to take external help"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLcT5K4a4aV-",
        "colab_type": "code",
        "outputId": "8923e89a-f8cc-48d8-9210-6f2f9d13833b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# We'd need to convert it into Numpy! Remember above we have converted it into tensors already\n",
        "train_data = train.train_data\n",
        "train_data = train.transform(train_data.numpy())\n",
        "\n",
        "print('[Train]')\n",
        "print(' - Numpy Shape:', train.train_data.cpu().numpy().shape)\n",
        "print(' - Tensor Shape:', train.train_data.size())\n",
        "print(' - min:', torch.min(train_data))\n",
        "print(' - max:', torch.max(train_data))\n",
        "print(' - mean:', torch.mean(train_data))\n",
        "print(' - std:', torch.std(train_data))\n",
        "print(' - var:', torch.var(train_data))\n",
        "\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "print(images.shape)\n",
        "print(labels.shape) # Each sample image is 28x28\n",
        "\n",
        "# Let's visualize some of the images\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#plt.imshow(images[0].numpy().squeeze(), cmap='gray_r'))\n",
        "print(images.shape)\n",
        "print(labels.shape) # Each sample image is 28x28\n",
        "\n",
        "# Let's visualize some of the images\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.imshow(images[0].numpy().squeeze(), cmap='gray_r')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:55: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[Train]\n",
            " - Numpy Shape: (60000, 28, 28)\n",
            " - Tensor Shape: torch.Size([60000, 28, 28])\n",
            " - min: tensor(-0.4242)\n",
            " - max: tensor(2.8215)\n",
            " - mean: tensor(0.0009)\n",
            " - std: tensor(1.0000)\n",
            " - var: tensor(1.0001)\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5skB97zIJQQe",
        "colab_type": "code",
        "outputId": "04a41052-605e-4370-a19c-c13e05d79f40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1,28,28))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
            "cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 12, 26, 26]             120\n",
            "              ReLU-2           [-1, 12, 26, 26]               0\n",
            "       BatchNorm2d-3           [-1, 12, 26, 26]              24\n",
            "            Conv2d-4           [-1, 12, 24, 24]           1,308\n",
            "              ReLU-5           [-1, 12, 24, 24]               0\n",
            "       BatchNorm2d-6           [-1, 12, 24, 24]              24\n",
            "         MaxPool2d-7           [-1, 12, 12, 12]               0\n",
            "            Conv2d-8           [-1, 14, 10, 10]           1,526\n",
            "              ReLU-9           [-1, 14, 10, 10]               0\n",
            "      BatchNorm2d-10           [-1, 14, 10, 10]              28\n",
            "           Conv2d-11             [-1, 16, 8, 8]           2,032\n",
            "             ReLU-12             [-1, 16, 8, 8]               0\n",
            "      BatchNorm2d-13             [-1, 16, 8, 8]              32\n",
            "           Conv2d-14             [-1, 16, 8, 8]           2,320\n",
            "             ReLU-15             [-1, 16, 8, 8]               0\n",
            "      BatchNorm2d-16             [-1, 16, 8, 8]              32\n",
            "           Conv2d-17             [-1, 16, 6, 6]           2,320\n",
            "             ReLU-18             [-1, 16, 6, 6]               0\n",
            "      BatchNorm2d-19             [-1, 16, 6, 6]              32\n",
            "        AvgPool2d-20             [-1, 16, 1, 1]               0\n",
            "           Conv2d-21             [-1, 10, 1, 1]             170\n",
            "================================================================\n",
            "Total params: 9,968\n",
            "Trainable params: 9,968\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.45\n",
            "Params size (MB): 0.04\n",
            "Estimated Total Size (MB): 0.49\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1__x_SbrL7z3",
        "colab_type": "text"
      },
      "source": [
        "# Training \n",
        "\n",
        "Looking at logs can be boring, so we'll introduce **tqdm** progressbar to get cooler logs. \n",
        "\n",
        "Let's write train functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbkF2nN_LYIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "train_losses = []\n",
        "train_acc = []\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "  #print('\\n total number of train_loader items', len(train_loader.dataset))\n",
        "  #print('train_loader Claases', train_loader.dataset.classes)\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader)\n",
        "  correct = 0\n",
        "  processed = 0\n",
        "  for batch_idx, (data, target) in enumerate(pbar):\n",
        "    # get samples\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Init\n",
        "    optimizer.zero_grad()\n",
        "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. \n",
        "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model(data)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = F.nll_loss(y_pred, target)\n",
        "    train_losses.append(loss)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update pbar-tqdm\n",
        "    \n",
        "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    processed += len(data)\n",
        "\n",
        "    pbar.set_description(desc= f'Epoch={epoch} Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
        "    train_acc.append(100*correct/processed)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbQaboA8zHrB",
        "colab_type": "text"
      },
      "source": [
        "**Testing**\n",
        "\n",
        "Looking at logs can be boring, so we'll introduce **tqdm** progressbar to get cooler logs. \n",
        "\n",
        "Let's write test functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkkM83Kjys9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "test_losses = []\n",
        "test_acc = []\n",
        "def test(model, device, test_loader,misclassify):\n",
        "    #print('\\n total number of test_loader items', len(test_loader.dataset))\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "      \n",
        "            for i in range(len(pred)):\n",
        "                if pred[i] != target[i]:\n",
        "                   misclassify.append([data[i],pred[i],target[i]])\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    \n",
        "    test_acc.append(100. * correct / len(test_loader.dataset))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drokW8wWODKq",
        "colab_type": "text"
      },
      "source": [
        "# Let's Train and test our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMCFxeAKOB53",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "467a46fd-6d5c-4a03-fb7c-07b4238497dc"
      },
      "source": [
        "model =  Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "EPOCHS = 1\n",
        "misclassify = []\n",
        "for epoch in range(EPOCHS):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader,misclassify)\n",
        "\n",
        "print(len(misclassify))\n",
        "j =0\n",
        "fig = plt.figure(figsize=(15,15))\n",
        "for i in range(25):\n",
        "    ax = fig.add_subplot(7,4,1+j)\n",
        "    plt.imshow(misclassify[i][0].data.cpu().numpy().squeeze(),cmap='gray_r')\n",
        "    title = \"predicted: \" + str(misclassify[i][1].data.cpu().numpy()) + \"target : \" + str(misclassify[i][2].data.cpu().numpy())\n",
        "    ax.set_title(title)\n",
        "    j+=1\n",
        "plt.show()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch=0 Loss=2.381296157836914 Batch_id=0 Accuracy=4.69:   0%|          | 0/469 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch=0 Loss=2.381296157836914 Batch_id=0 Accuracy=4.69:   0%|          | 1/469 [00:00<03:02,  2.57it/s]\u001b[A\n",
            "Epoch=0 Loss=2.3775274753570557 Batch_id=1 Accuracy=5.86:   0%|          | 1/469 [00:00<03:02,  2.57it/s]\u001b[A\n",
            "Epoch=0 Loss=2.3428940773010254 Batch_id=2 Accuracy=6.51:   0%|          | 1/469 [00:00<03:02,  2.57it/s]\u001b[A\n",
            "Epoch=0 Loss=2.3089702129364014 Batch_id=3 Accuracy=6.84:   0%|          | 1/469 [00:00<03:02,  2.57it/s]\u001b[A\n",
            "Epoch=0 Loss=2.3089702129364014 Batch_id=3 Accuracy=6.84:   1%|          | 4/469 [00:00<02:12,  3.50it/s]\u001b[A\n",
            "Epoch=0 Loss=2.270969867706299 Batch_id=4 Accuracy=8.75:   1%|          | 4/469 [00:00<02:12,  3.50it/s] \u001b[A\n",
            "Epoch=0 Loss=2.24251651763916 Batch_id=5 Accuracy=9.77:   1%|          | 4/469 [00:00<02:12,  3.50it/s] \u001b[A\n",
            "Epoch=0 Loss=2.1788201332092285 Batch_id=6 Accuracy=12.50:   1%|          | 4/469 [00:00<02:12,  3.50it/s]\u001b[A\n",
            "Epoch=0 Loss=2.1788201332092285 Batch_id=6 Accuracy=12.50:   1%|▏         | 7/469 [00:00<01:37,  4.74it/s]\u001b[A\n",
            "Epoch=0 Loss=2.127599000930786 Batch_id=7 Accuracy=14.26:   1%|▏         | 7/469 [00:00<01:37,  4.74it/s] \u001b[A\n",
            "Epoch=0 Loss=2.1769466400146484 Batch_id=8 Accuracy=15.36:   1%|▏         | 7/469 [00:00<01:37,  4.74it/s]\u001b[A\n",
            "Epoch=0 Loss=2.1769466400146484 Batch_id=8 Accuracy=15.36:   2%|▏         | 9/469 [00:00<01:16,  5.99it/s]\u001b[A\n",
            "Epoch=0 Loss=2.141002655029297 Batch_id=9 Accuracy=16.33:   2%|▏         | 9/469 [00:00<01:16,  5.99it/s] \u001b[A\n",
            "Epoch=0 Loss=2.1038177013397217 Batch_id=10 Accuracy=17.05:   2%|▏         | 9/469 [00:00<01:16,  5.99it/s]\u001b[A\n",
            "Epoch=0 Loss=2.1038177013397217 Batch_id=10 Accuracy=17.05:   2%|▏         | 11/469 [00:00<01:01,  7.47it/s]\u001b[A\n",
            "Epoch=0 Loss=2.029998302459717 Batch_id=11 Accuracy=18.55:   2%|▏         | 11/469 [00:00<01:01,  7.47it/s] \u001b[A\n",
            "Epoch=0 Loss=2.0833795070648193 Batch_id=12 Accuracy=19.59:   2%|▏         | 11/469 [00:00<01:01,  7.47it/s]\u001b[A\n",
            "Epoch=0 Loss=2.0833795070648193 Batch_id=12 Accuracy=19.59:   3%|▎         | 13/469 [00:00<00:50,  9.10it/s]\u001b[A\n",
            "Epoch=0 Loss=1.9954484701156616 Batch_id=13 Accuracy=20.87:   3%|▎         | 13/469 [00:01<00:50,  9.10it/s]\u001b[A\n",
            "Epoch=0 Loss=1.984814167022705 Batch_id=14 Accuracy=21.61:   3%|▎         | 13/469 [00:01<00:50,  9.10it/s] \u001b[A\n",
            "Epoch=0 Loss=1.9836511611938477 Batch_id=15 Accuracy=22.80:   3%|▎         | 13/469 [00:01<00:50,  9.10it/s]\u001b[A\n",
            "Epoch=0 Loss=1.9836511611938477 Batch_id=15 Accuracy=22.80:   3%|▎         | 16/469 [00:01<00:40, 11.27it/s]\u001b[A\n",
            "Epoch=0 Loss=2.0045411586761475 Batch_id=16 Accuracy=23.62:   3%|▎         | 16/469 [00:01<00:40, 11.27it/s]\u001b[A\n",
            "Epoch=0 Loss=1.8753734827041626 Batch_id=17 Accuracy=24.91:   3%|▎         | 16/469 [00:01<00:40, 11.27it/s]\u001b[A\n",
            "Epoch=0 Loss=1.902934193611145 Batch_id=18 Accuracy=25.53:   3%|▎         | 16/469 [00:01<00:40, 11.27it/s] \u001b[A\n",
            "Epoch=0 Loss=1.902934193611145 Batch_id=18 Accuracy=25.53:   4%|▍         | 19/469 [00:01<00:33, 13.45it/s]\u001b[A\n",
            "Epoch=0 Loss=1.8828421831130981 Batch_id=19 Accuracy=26.29:   4%|▍         | 19/469 [00:01<00:33, 13.45it/s]\u001b[A\n",
            "Epoch=0 Loss=1.8419170379638672 Batch_id=20 Accuracy=27.05:   4%|▍         | 19/469 [00:01<00:33, 13.45it/s]\u001b[A\n",
            "Epoch=0 Loss=1.8243789672851562 Batch_id=21 Accuracy=27.70:   4%|▍         | 19/469 [00:01<00:33, 13.45it/s]\u001b[A\n",
            "Epoch=0 Loss=1.8243789672851562 Batch_id=21 Accuracy=27.70:   5%|▍         | 22/469 [00:01<00:28, 15.88it/s]\u001b[A\n",
            "Epoch=0 Loss=1.7845219373703003 Batch_id=22 Accuracy=28.70:   5%|▍         | 22/469 [00:01<00:28, 15.88it/s]\u001b[A\n",
            "Epoch=0 Loss=1.756271481513977 Batch_id=23 Accuracy=29.59:   5%|▍         | 22/469 [00:01<00:28, 15.88it/s] \u001b[A\n",
            "Epoch=0 Loss=1.7282661199569702 Batch_id=24 Accuracy=30.34:   5%|▍         | 22/469 [00:01<00:28, 15.88it/s]\u001b[A\n",
            "Epoch=0 Loss=1.7282661199569702 Batch_id=24 Accuracy=30.34:   5%|▌         | 25/469 [00:01<00:24, 18.08it/s]\u001b[A\n",
            "Epoch=0 Loss=1.7607613801956177 Batch_id=25 Accuracy=31.13:   5%|▌         | 25/469 [00:01<00:24, 18.08it/s]\u001b[A\n",
            "Epoch=0 Loss=1.682708740234375 Batch_id=26 Accuracy=32.26:   5%|▌         | 25/469 [00:01<00:24, 18.08it/s] \u001b[A\n",
            "Epoch=0 Loss=1.6445298194885254 Batch_id=27 Accuracy=33.29:   5%|▌         | 25/469 [00:01<00:24, 18.08it/s]\u001b[A\n",
            "Epoch=0 Loss=1.6445298194885254 Batch_id=27 Accuracy=33.29:   6%|▌         | 28/469 [00:01<00:23, 19.04it/s]\u001b[A\n",
            "Epoch=0 Loss=1.6009929180145264 Batch_id=28 Accuracy=34.29:   6%|▌         | 28/469 [00:01<00:23, 19.04it/s]\u001b[A\n",
            "Epoch=0 Loss=1.6203997135162354 Batch_id=29 Accuracy=35.21:   6%|▌         | 28/469 [00:01<00:23, 19.04it/s]\u001b[A\n",
            "Epoch=0 Loss=1.5885815620422363 Batch_id=30 Accuracy=36.19:   6%|▌         | 28/469 [00:01<00:23, 19.04it/s]\u001b[A\n",
            "Epoch=0 Loss=1.5885815620422363 Batch_id=30 Accuracy=36.19:   7%|▋         | 31/469 [00:01<00:21, 19.93it/s]\u001b[A\n",
            "Epoch=0 Loss=1.663766860961914 Batch_id=31 Accuracy=36.94:   7%|▋         | 31/469 [00:01<00:21, 19.93it/s] \u001b[A\n",
            "Epoch=0 Loss=1.6207588911056519 Batch_id=32 Accuracy=37.90:   7%|▋         | 31/469 [00:01<00:21, 19.93it/s]\u001b[A\n",
            "Epoch=0 Loss=1.5575484037399292 Batch_id=33 Accuracy=38.65:   7%|▋         | 31/469 [00:01<00:21, 19.93it/s]\u001b[A\n",
            "Epoch=0 Loss=1.5575484037399292 Batch_id=33 Accuracy=38.65:   7%|▋         | 34/469 [00:01<00:21, 20.62it/s]\u001b[A\n",
            "Epoch=0 Loss=1.5024046897888184 Batch_id=34 Accuracy=39.44:   7%|▋         | 34/469 [00:01<00:21, 20.62it/s]\u001b[A\n",
            "Epoch=0 Loss=1.4961172342300415 Batch_id=35 Accuracy=40.08:   7%|▋         | 34/469 [00:01<00:21, 20.62it/s]\u001b[A\n",
            "Epoch=0 Loss=1.5371415615081787 Batch_id=36 Accuracy=40.67:   7%|▋         | 34/469 [00:01<00:21, 20.62it/s]\u001b[A\n",
            "Epoch=0 Loss=1.5371415615081787 Batch_id=36 Accuracy=40.67:   8%|▊         | 37/469 [00:01<00:20, 21.22it/s]\u001b[A\n",
            "Epoch=0 Loss=1.5204023122787476 Batch_id=37 Accuracy=41.18:   8%|▊         | 37/469 [00:02<00:20, 21.22it/s]\u001b[A\n",
            "Epoch=0 Loss=1.400169849395752 Batch_id=38 Accuracy=41.97:   8%|▊         | 37/469 [00:02<00:20, 21.22it/s] \u001b[A\n",
            "Epoch=0 Loss=1.437900185585022 Batch_id=39 Accuracy=42.60:   8%|▊         | 37/469 [00:02<00:20, 21.22it/s]\u001b[A\n",
            "Epoch=0 Loss=1.437900185585022 Batch_id=39 Accuracy=42.60:   9%|▊         | 40/469 [00:02<00:20, 21.14it/s]\u001b[A\n",
            "Epoch=0 Loss=1.3978451490402222 Batch_id=40 Accuracy=43.39:   9%|▊         | 40/469 [00:02<00:20, 21.14it/s]\u001b[A\n",
            "Epoch=0 Loss=1.3556599617004395 Batch_id=41 Accuracy=44.10:   9%|▊         | 40/469 [00:02<00:20, 21.14it/s]\u001b[A\n",
            "Epoch=0 Loss=1.4187812805175781 Batch_id=42 Accuracy=44.60:   9%|▊         | 40/469 [00:02<00:20, 21.14it/s]\u001b[A\n",
            "Epoch=0 Loss=1.4187812805175781 Batch_id=42 Accuracy=44.60:   9%|▉         | 43/469 [00:02<00:19, 21.89it/s]\u001b[A\n",
            "Epoch=0 Loss=1.2844609022140503 Batch_id=43 Accuracy=45.35:   9%|▉         | 43/469 [00:02<00:19, 21.89it/s]\u001b[A\n",
            "Epoch=0 Loss=1.3225018978118896 Batch_id=44 Accuracy=45.92:   9%|▉         | 43/469 [00:02<00:19, 21.89it/s]\u001b[A\n",
            "Epoch=0 Loss=1.385249137878418 Batch_id=45 Accuracy=46.33:   9%|▉         | 43/469 [00:02<00:19, 21.89it/s] \u001b[A\n",
            "Epoch=0 Loss=1.385249137878418 Batch_id=45 Accuracy=46.33:  10%|▉         | 46/469 [00:02<00:18, 23.45it/s]\u001b[A\n",
            "Epoch=0 Loss=1.2723302841186523 Batch_id=46 Accuracy=46.78:  10%|▉         | 46/469 [00:02<00:18, 23.45it/s]\u001b[A\n",
            "Epoch=0 Loss=1.2232673168182373 Batch_id=47 Accuracy=47.46:  10%|▉         | 46/469 [00:02<00:18, 23.45it/s]\u001b[A\n",
            "Epoch=0 Loss=1.1136865615844727 Batch_id=48 Accuracy=48.18:  10%|▉         | 46/469 [00:02<00:18, 23.45it/s]\u001b[A\n",
            "Epoch=0 Loss=1.1136865615844727 Batch_id=48 Accuracy=48.18:  10%|█         | 49/469 [00:02<00:17, 24.33it/s]\u001b[A\n",
            "Epoch=0 Loss=1.2485064268112183 Batch_id=49 Accuracy=48.73:  10%|█         | 49/469 [00:02<00:17, 24.33it/s]\u001b[A\n",
            "Epoch=0 Loss=1.1522244215011597 Batch_id=50 Accuracy=49.28:  10%|█         | 49/469 [00:02<00:17, 24.33it/s]\u001b[A\n",
            "Epoch=0 Loss=1.1708128452301025 Batch_id=51 Accuracy=49.76:  10%|█         | 49/469 [00:02<00:17, 24.33it/s]\u001b[A\n",
            "Epoch=0 Loss=1.1708128452301025 Batch_id=51 Accuracy=49.76:  11%|█         | 52/469 [00:02<00:16, 24.63it/s]\u001b[A\n",
            "Epoch=0 Loss=1.2439619302749634 Batch_id=52 Accuracy=50.18:  11%|█         | 52/469 [00:02<00:16, 24.63it/s]\u001b[A\n",
            "Epoch=0 Loss=1.1945645809173584 Batch_id=53 Accuracy=50.56:  11%|█         | 52/469 [00:02<00:16, 24.63it/s]\u001b[A\n",
            "Epoch=0 Loss=1.1039096117019653 Batch_id=54 Accuracy=50.98:  11%|█         | 52/469 [00:02<00:16, 24.63it/s]\u001b[A\n",
            "Epoch=0 Loss=1.1039096117019653 Batch_id=54 Accuracy=50.98:  12%|█▏        | 55/469 [00:02<00:16, 25.11it/s]\u001b[A\n",
            "Epoch=0 Loss=1.100952386856079 Batch_id=55 Accuracy=51.48:  12%|█▏        | 55/469 [00:02<00:16, 25.11it/s] \u001b[A\n",
            "Epoch=0 Loss=1.111641526222229 Batch_id=56 Accuracy=51.93:  12%|█▏        | 55/469 [00:02<00:16, 25.11it/s]\u001b[A\n",
            "Epoch=0 Loss=1.1187357902526855 Batch_id=57 Accuracy=52.34:  12%|█▏        | 55/469 [00:02<00:16, 25.11it/s]\u001b[A\n",
            "Epoch=0 Loss=1.1187357902526855 Batch_id=57 Accuracy=52.34:  12%|█▏        | 58/469 [00:02<00:15, 25.74it/s]\u001b[A\n",
            "Epoch=0 Loss=1.0561695098876953 Batch_id=58 Accuracy=52.75:  12%|█▏        | 58/469 [00:02<00:15, 25.74it/s]\u001b[A\n",
            "Epoch=0 Loss=1.1294766664505005 Batch_id=59 Accuracy=53.10:  12%|█▏        | 58/469 [00:02<00:15, 25.74it/s]\u001b[A\n",
            "Epoch=0 Loss=1.1332658529281616 Batch_id=60 Accuracy=53.39:  12%|█▏        | 58/469 [00:02<00:15, 25.74it/s]\u001b[A\n",
            "Epoch=0 Loss=1.1332658529281616 Batch_id=60 Accuracy=53.39:  13%|█▎        | 61/469 [00:02<00:15, 26.11it/s]\u001b[A\n",
            "Epoch=0 Loss=0.9950207471847534 Batch_id=61 Accuracy=53.76:  13%|█▎        | 61/469 [00:02<00:15, 26.11it/s]\u001b[A\n",
            "Epoch=0 Loss=0.993901252746582 Batch_id=62 Accuracy=54.10:  13%|█▎        | 61/469 [00:02<00:15, 26.11it/s] \u001b[A\n",
            "Epoch=0 Loss=0.9941157102584839 Batch_id=63 Accuracy=54.48:  13%|█▎        | 61/469 [00:03<00:15, 26.11it/s]\u001b[A\n",
            "Epoch=0 Loss=0.9941157102584839 Batch_id=63 Accuracy=54.48:  14%|█▎        | 64/469 [00:03<00:15, 26.62it/s]\u001b[A\n",
            "Epoch=0 Loss=1.0356688499450684 Batch_id=64 Accuracy=54.76:  14%|█▎        | 64/469 [00:03<00:15, 26.62it/s]\u001b[A\n",
            "Epoch=0 Loss=0.9425738453865051 Batch_id=65 Accuracy=55.22:  14%|█▎        | 64/469 [00:03<00:15, 26.62it/s]\u001b[A\n",
            "Epoch=0 Loss=0.9925122261047363 Batch_id=66 Accuracy=55.60:  14%|█▎        | 64/469 [00:03<00:15, 26.62it/s]\u001b[A\n",
            "Epoch=0 Loss=0.9925122261047363 Batch_id=66 Accuracy=55.60:  14%|█▍        | 67/469 [00:03<00:15, 25.80it/s]\u001b[A\n",
            "Epoch=0 Loss=0.9321372509002686 Batch_id=67 Accuracy=55.89:  14%|█▍        | 67/469 [00:03<00:15, 25.80it/s]\u001b[A\n",
            "Epoch=0 Loss=0.9139062166213989 Batch_id=68 Accuracy=56.26:  14%|█▍        | 67/469 [00:03<00:15, 25.80it/s]\u001b[A\n",
            "Epoch=0 Loss=0.7873839735984802 Batch_id=69 Accuracy=56.72:  14%|█▍        | 67/469 [00:03<00:15, 25.80it/s]\u001b[A\n",
            "Epoch=0 Loss=0.7873839735984802 Batch_id=69 Accuracy=56.72:  15%|█▍        | 70/469 [00:03<00:16, 24.81it/s]\u001b[A\n",
            "Epoch=0 Loss=0.7995712161064148 Batch_id=70 Accuracy=57.15:  15%|█▍        | 70/469 [00:03<00:16, 24.81it/s]\u001b[A\n",
            "Epoch=0 Loss=0.7453973889350891 Batch_id=71 Accuracy=57.61:  15%|█▍        | 70/469 [00:03<00:16, 24.81it/s]\u001b[A\n",
            "Epoch=0 Loss=0.7705807685852051 Batch_id=72 Accuracy=57.94:  15%|█▍        | 70/469 [00:03<00:16, 24.81it/s]\u001b[A\n",
            "Epoch=0 Loss=0.7705807685852051 Batch_id=72 Accuracy=57.94:  16%|█▌        | 73/469 [00:03<00:15, 24.82it/s]\u001b[A\n",
            "Epoch=0 Loss=0.8022661209106445 Batch_id=73 Accuracy=58.33:  16%|█▌        | 73/469 [00:03<00:15, 24.82it/s]\u001b[A\n",
            "Epoch=0 Loss=0.8008961081504822 Batch_id=74 Accuracy=58.71:  16%|█▌        | 73/469 [00:03<00:15, 24.82it/s]\u001b[A\n",
            "Epoch=0 Loss=0.849065899848938 Batch_id=75 Accuracy=59.08:  16%|█▌        | 73/469 [00:03<00:15, 24.82it/s] \u001b[A\n",
            "Epoch=0 Loss=0.849065899848938 Batch_id=75 Accuracy=59.08:  16%|█▌        | 76/469 [00:03<00:16, 23.71it/s]\u001b[A\n",
            "Epoch=0 Loss=0.8210271596908569 Batch_id=76 Accuracy=59.46:  16%|█▌        | 76/469 [00:03<00:16, 23.71it/s]\u001b[A\n",
            "Epoch=0 Loss=0.745806097984314 Batch_id=77 Accuracy=59.81:  16%|█▌        | 76/469 [00:03<00:16, 23.71it/s] \u001b[A\n",
            "Epoch=0 Loss=0.8295202255249023 Batch_id=78 Accuracy=60.08:  16%|█▌        | 76/469 [00:03<00:16, 23.71it/s]\u001b[A\n",
            "Epoch=0 Loss=0.8295202255249023 Batch_id=78 Accuracy=60.08:  17%|█▋        | 79/469 [00:03<00:18, 21.07it/s]\u001b[A\n",
            "Epoch=0 Loss=0.761530339717865 Batch_id=79 Accuracy=60.37:  17%|█▋        | 79/469 [00:03<00:18, 21.07it/s] \u001b[A\n",
            "Epoch=0 Loss=0.6156611442565918 Batch_id=80 Accuracy=60.76:  17%|█▋        | 79/469 [00:03<00:18, 21.07it/s]\u001b[A\n",
            "Epoch=0 Loss=0.7221243381500244 Batch_id=81 Accuracy=61.07:  17%|█▋        | 79/469 [00:03<00:18, 21.07it/s]\u001b[A\n",
            "Epoch=0 Loss=0.7221243381500244 Batch_id=81 Accuracy=61.07:  17%|█▋        | 82/469 [00:03<00:17, 21.75it/s]\u001b[A\n",
            "Epoch=0 Loss=0.6428912281990051 Batch_id=82 Accuracy=61.42:  17%|█▋        | 82/469 [00:03<00:17, 21.75it/s]\u001b[A\n",
            "Epoch=0 Loss=0.6629939675331116 Batch_id=83 Accuracy=61.71:  17%|█▋        | 82/469 [00:03<00:17, 21.75it/s]\u001b[A\n",
            "Epoch=0 Loss=0.587983250617981 Batch_id=84 Accuracy=62.05:  17%|█▋        | 82/469 [00:03<00:17, 21.75it/s] \u001b[A\n",
            "Epoch=0 Loss=0.587983250617981 Batch_id=84 Accuracy=62.05:  18%|█▊        | 85/469 [00:04<00:18, 21.24it/s]\u001b[A\n",
            "Epoch=0 Loss=0.6788510084152222 Batch_id=85 Accuracy=62.32:  18%|█▊        | 85/469 [00:04<00:18, 21.24it/s]\u001b[A\n",
            "Epoch=0 Loss=0.6888116598129272 Batch_id=86 Accuracy=62.60:  18%|█▊        | 85/469 [00:04<00:18, 21.24it/s]\u001b[A\n",
            "Epoch=0 Loss=0.7129645347595215 Batch_id=87 Accuracy=62.83:  18%|█▊        | 85/469 [00:04<00:18, 21.24it/s]\u001b[A\n",
            "Epoch=0 Loss=0.7129645347595215 Batch_id=87 Accuracy=62.83:  19%|█▉        | 88/469 [00:04<00:17, 21.83it/s]\u001b[A\n",
            "Epoch=0 Loss=0.6700039505958557 Batch_id=88 Accuracy=63.06:  19%|█▉        | 88/469 [00:04<00:17, 21.83it/s]\u001b[A\n",
            "Epoch=0 Loss=0.5945464372634888 Batch_id=89 Accuracy=63.40:  19%|█▉        | 88/469 [00:04<00:17, 21.83it/s]\u001b[A\n",
            "Epoch=0 Loss=0.6418642997741699 Batch_id=90 Accuracy=63.66:  19%|█▉        | 88/469 [00:04<00:17, 21.83it/s]\u001b[A\n",
            "Epoch=0 Loss=0.6418642997741699 Batch_id=90 Accuracy=63.66:  19%|█▉        | 91/469 [00:04<00:17, 21.59it/s]\u001b[A\n",
            "Epoch=0 Loss=0.5606589317321777 Batch_id=91 Accuracy=63.98:  19%|█▉        | 91/469 [00:04<00:17, 21.59it/s]\u001b[A\n",
            "Epoch=0 Loss=0.5181953310966492 Batch_id=92 Accuracy=64.31:  19%|█▉        | 91/469 [00:04<00:17, 21.59it/s]\u001b[A\n",
            "Epoch=0 Loss=0.5900518894195557 Batch_id=93 Accuracy=64.57:  19%|█▉        | 91/469 [00:04<00:17, 21.59it/s]\u001b[A\n",
            "Epoch=0 Loss=0.5900518894195557 Batch_id=93 Accuracy=64.57:  20%|██        | 94/469 [00:04<00:16, 22.93it/s]\u001b[A\n",
            "Epoch=0 Loss=0.5289838910102844 Batch_id=94 Accuracy=64.85:  20%|██        | 94/469 [00:04<00:16, 22.93it/s]\u001b[A\n",
            "Epoch=0 Loss=0.49886950850486755 Batch_id=95 Accuracy=65.14:  20%|██        | 94/469 [00:04<00:16, 22.93it/s]\u001b[A\n",
            "Epoch=0 Loss=0.4826977550983429 Batch_id=96 Accuracy=65.43:  20%|██        | 94/469 [00:04<00:16, 22.93it/s] \u001b[A\n",
            "Epoch=0 Loss=0.4826977550983429 Batch_id=96 Accuracy=65.43:  21%|██        | 97/469 [00:04<00:15, 23.77it/s]\u001b[A\n",
            "Epoch=0 Loss=0.520046055316925 Batch_id=97 Accuracy=65.70:  21%|██        | 97/469 [00:04<00:15, 23.77it/s] \u001b[A\n",
            "Epoch=0 Loss=0.5074686408042908 Batch_id=98 Accuracy=65.98:  21%|██        | 97/469 [00:04<00:15, 23.77it/s]\u001b[A\n",
            "Epoch=0 Loss=0.46256059408187866 Batch_id=99 Accuracy=66.23:  21%|██        | 97/469 [00:04<00:15, 23.77it/s]\u001b[A\n",
            "Epoch=0 Loss=0.46256059408187866 Batch_id=99 Accuracy=66.23:  21%|██▏       | 100/469 [00:04<00:15, 24.25it/s]\u001b[A\n",
            "Epoch=0 Loss=0.4530320465564728 Batch_id=100 Accuracy=66.51:  21%|██▏       | 100/469 [00:04<00:15, 24.25it/s]\u001b[A\n",
            "Epoch=0 Loss=0.4485231935977936 Batch_id=101 Accuracy=66.79:  21%|██▏       | 100/469 [00:04<00:15, 24.25it/s]\u001b[A\n",
            "Epoch=0 Loss=0.5007786154747009 Batch_id=102 Accuracy=67.06:  21%|██▏       | 100/469 [00:04<00:15, 24.25it/s]\u001b[A\n",
            "Epoch=0 Loss=0.5007786154747009 Batch_id=102 Accuracy=67.06:  22%|██▏       | 103/469 [00:04<00:16, 22.84it/s]\u001b[A\n",
            "Epoch=0 Loss=0.47677361965179443 Batch_id=103 Accuracy=67.30:  22%|██▏       | 103/469 [00:04<00:16, 22.84it/s]\u001b[A\n",
            "Epoch=0 Loss=0.5117757320404053 Batch_id=104 Accuracy=67.54:  22%|██▏       | 103/469 [00:04<00:16, 22.84it/s] \u001b[A\n",
            "Epoch=0 Loss=0.47477802634239197 Batch_id=105 Accuracy=67.77:  22%|██▏       | 103/469 [00:04<00:16, 22.84it/s]\u001b[A\n",
            "Epoch=0 Loss=0.47477802634239197 Batch_id=105 Accuracy=67.77:  23%|██▎       | 106/469 [00:04<00:16, 22.36it/s]\u001b[A\n",
            "Epoch=0 Loss=0.46153417229652405 Batch_id=106 Accuracy=67.98:  23%|██▎       | 106/469 [00:04<00:16, 22.36it/s]\u001b[A\n",
            "Epoch=0 Loss=0.42201536893844604 Batch_id=107 Accuracy=68.20:  23%|██▎       | 106/469 [00:04<00:16, 22.36it/s]\u001b[A\n",
            "Epoch=0 Loss=0.4600859582424164 Batch_id=108 Accuracy=68.43:  23%|██▎       | 106/469 [00:05<00:16, 22.36it/s] \u001b[A\n",
            "Epoch=0 Loss=0.4600859582424164 Batch_id=108 Accuracy=68.43:  23%|██▎       | 109/469 [00:05<00:15, 22.77it/s]\u001b[A\n",
            "Epoch=0 Loss=0.38577890396118164 Batch_id=109 Accuracy=68.68:  23%|██▎       | 109/469 [00:05<00:15, 22.77it/s]\u001b[A\n",
            "Epoch=0 Loss=0.3927585780620575 Batch_id=110 Accuracy=68.92:  23%|██▎       | 109/469 [00:05<00:15, 22.77it/s] \u001b[A\n",
            "Epoch=0 Loss=0.4310169816017151 Batch_id=111 Accuracy=69.13:  23%|██▎       | 109/469 [00:05<00:15, 22.77it/s]\u001b[A\n",
            "Epoch=0 Loss=0.4310169816017151 Batch_id=111 Accuracy=69.13:  24%|██▍       | 112/469 [00:05<00:15, 23.71it/s]\u001b[A\n",
            "Epoch=0 Loss=0.3629656136035919 Batch_id=112 Accuracy=69.37:  24%|██▍       | 112/469 [00:05<00:15, 23.71it/s]\u001b[A\n",
            "Epoch=0 Loss=0.4630298316478729 Batch_id=113 Accuracy=69.57:  24%|██▍       | 112/469 [00:05<00:15, 23.71it/s]\u001b[A\n",
            "Epoch=0 Loss=0.3936476409435272 Batch_id=114 Accuracy=69.78:  24%|██▍       | 112/469 [00:05<00:15, 23.71it/s]\u001b[A\n",
            "Epoch=0 Loss=0.3936476409435272 Batch_id=114 Accuracy=69.78:  25%|██▍       | 115/469 [00:05<00:14, 24.77it/s]\u001b[A\n",
            "Epoch=0 Loss=0.29927289485931396 Batch_id=115 Accuracy=70.02:  25%|██▍       | 115/469 [00:05<00:14, 24.77it/s]\u001b[A\n",
            "Epoch=0 Loss=0.3681658208370209 Batch_id=116 Accuracy=70.23:  25%|██▍       | 115/469 [00:05<00:14, 24.77it/s] \u001b[A\n",
            "Epoch=0 Loss=0.35530152916908264 Batch_id=117 Accuracy=70.45:  25%|██▍       | 115/469 [00:05<00:14, 24.77it/s]\u001b[A\n",
            "Epoch=0 Loss=0.35530152916908264 Batch_id=117 Accuracy=70.45:  25%|██▌       | 118/469 [00:05<00:13, 25.31it/s]\u001b[A\n",
            "Epoch=0 Loss=0.3897397816181183 Batch_id=118 Accuracy=70.63:  25%|██▌       | 118/469 [00:05<00:13, 25.31it/s] \u001b[A\n",
            "Epoch=0 Loss=0.38974952697753906 Batch_id=119 Accuracy=70.82:  25%|██▌       | 118/469 [00:05<00:13, 25.31it/s]\u001b[A\n",
            "Epoch=0 Loss=0.38071390986442566 Batch_id=120 Accuracy=70.99:  25%|██▌       | 118/469 [00:05<00:13, 25.31it/s]\u001b[A\n",
            "Epoch=0 Loss=0.38071390986442566 Batch_id=120 Accuracy=70.99:  26%|██▌       | 121/469 [00:05<00:14, 23.32it/s]\u001b[A\n",
            "Epoch=0 Loss=0.32183316349983215 Batch_id=121 Accuracy=71.18:  26%|██▌       | 121/469 [00:05<00:14, 23.32it/s]\u001b[A\n",
            "Epoch=0 Loss=0.3177809715270996 Batch_id=122 Accuracy=71.39:  26%|██▌       | 121/469 [00:05<00:14, 23.32it/s] \u001b[A\n",
            "Epoch=0 Loss=0.42670971155166626 Batch_id=123 Accuracy=71.56:  26%|██▌       | 121/469 [00:05<00:14, 23.32it/s]\u001b[A\n",
            "Epoch=0 Loss=0.42670971155166626 Batch_id=123 Accuracy=71.56:  26%|██▋       | 124/469 [00:05<00:15, 21.94it/s]\u001b[A\n",
            "Epoch=0 Loss=0.3889642357826233 Batch_id=124 Accuracy=71.72:  26%|██▋       | 124/469 [00:05<00:15, 21.94it/s] \u001b[A\n",
            "Epoch=0 Loss=0.2963075637817383 Batch_id=125 Accuracy=71.91:  26%|██▋       | 124/469 [00:05<00:15, 21.94it/s]\u001b[A\n",
            "Epoch=0 Loss=0.30229413509368896 Batch_id=126 Accuracy=72.08:  26%|██▋       | 124/469 [00:05<00:15, 21.94it/s]\u001b[A\n",
            "Epoch=0 Loss=0.30229413509368896 Batch_id=126 Accuracy=72.08:  27%|██▋       | 127/469 [00:05<00:16, 20.42it/s]\u001b[A\n",
            "Epoch=0 Loss=0.2513676583766937 Batch_id=127 Accuracy=72.29:  27%|██▋       | 127/469 [00:05<00:16, 20.42it/s] \u001b[A\n",
            "Epoch=0 Loss=0.31000304222106934 Batch_id=128 Accuracy=72.46:  27%|██▋       | 127/469 [00:05<00:16, 20.42it/s]\u001b[A\n",
            "Epoch=0 Loss=0.26826009154319763 Batch_id=129 Accuracy=72.67:  27%|██▋       | 127/469 [00:05<00:16, 20.42it/s]\u001b[A\n",
            "Epoch=0 Loss=0.26826009154319763 Batch_id=129 Accuracy=72.67:  28%|██▊       | 130/469 [00:05<00:16, 20.42it/s]\u001b[A\n",
            "Epoch=0 Loss=0.3561417758464813 Batch_id=130 Accuracy=72.82:  28%|██▊       | 130/469 [00:06<00:16, 20.42it/s] \u001b[A\n",
            "Epoch=0 Loss=0.25913840532302856 Batch_id=131 Accuracy=72.99:  28%|██▊       | 130/469 [00:06<00:16, 20.42it/s]\u001b[A\n",
            "Epoch=0 Loss=0.39170214533805847 Batch_id=132 Accuracy=73.12:  28%|██▊       | 130/469 [00:06<00:16, 20.42it/s]\u001b[A\n",
            "Epoch=0 Loss=0.39170214533805847 Batch_id=132 Accuracy=73.12:  28%|██▊       | 133/469 [00:06<00:16, 20.95it/s]\u001b[A\n",
            "Epoch=0 Loss=0.30620333552360535 Batch_id=133 Accuracy=73.29:  28%|██▊       | 133/469 [00:06<00:16, 20.95it/s]\u001b[A\n",
            "Epoch=0 Loss=0.32523366808891296 Batch_id=134 Accuracy=73.45:  28%|██▊       | 133/469 [00:06<00:16, 20.95it/s]\u001b[A\n",
            "Epoch=0 Loss=0.2838843762874603 Batch_id=135 Accuracy=73.63:  28%|██▊       | 133/469 [00:06<00:16, 20.95it/s] \u001b[A\n",
            "Epoch=0 Loss=0.2838843762874603 Batch_id=135 Accuracy=73.63:  29%|██▉       | 136/469 [00:06<00:15, 20.90it/s]\u001b[A\n",
            "Epoch=0 Loss=0.342093825340271 Batch_id=136 Accuracy=73.77:  29%|██▉       | 136/469 [00:06<00:15, 20.90it/s] \u001b[A\n",
            "Epoch=0 Loss=0.2908986210823059 Batch_id=137 Accuracy=73.93:  29%|██▉       | 136/469 [00:06<00:15, 20.90it/s]\u001b[A\n",
            "Epoch=0 Loss=0.27958056330680847 Batch_id=138 Accuracy=74.08:  29%|██▉       | 136/469 [00:06<00:15, 20.90it/s]\u001b[A\n",
            "Epoch=0 Loss=0.27958056330680847 Batch_id=138 Accuracy=74.08:  30%|██▉       | 139/469 [00:06<00:15, 20.80it/s]\u001b[A\n",
            "Epoch=0 Loss=0.26893770694732666 Batch_id=139 Accuracy=74.25:  30%|██▉       | 139/469 [00:06<00:15, 20.80it/s]\u001b[A\n",
            "Epoch=0 Loss=0.2673831582069397 Batch_id=140 Accuracy=74.41:  30%|██▉       | 139/469 [00:06<00:15, 20.80it/s] \u001b[A\n",
            "Epoch=0 Loss=0.2598860263824463 Batch_id=141 Accuracy=74.57:  30%|██▉       | 139/469 [00:06<00:15, 20.80it/s]\u001b[A\n",
            "Epoch=0 Loss=0.2598860263824463 Batch_id=141 Accuracy=74.57:  30%|███       | 142/469 [00:06<00:15, 20.88it/s]\u001b[A\n",
            "Epoch=0 Loss=0.22021928429603577 Batch_id=142 Accuracy=74.73:  30%|███       | 142/469 [00:06<00:15, 20.88it/s]\u001b[A\n",
            "Epoch=0 Loss=0.26519617438316345 Batch_id=143 Accuracy=74.88:  30%|███       | 142/469 [00:06<00:15, 20.88it/s]\u001b[A\n",
            "Epoch=0 Loss=0.25178220868110657 Batch_id=144 Accuracy=75.02:  30%|███       | 142/469 [00:06<00:15, 20.88it/s]\u001b[A\n",
            "Epoch=0 Loss=0.25178220868110657 Batch_id=144 Accuracy=75.02:  31%|███       | 145/469 [00:06<00:15, 21.20it/s]\u001b[A\n",
            "Epoch=0 Loss=0.27620959281921387 Batch_id=145 Accuracy=75.16:  31%|███       | 145/469 [00:06<00:15, 21.20it/s]\u001b[A\n",
            "Epoch=0 Loss=0.3053453266620636 Batch_id=146 Accuracy=75.29:  31%|███       | 145/469 [00:06<00:15, 21.20it/s] \u001b[A\n",
            "Epoch=0 Loss=0.28702956438064575 Batch_id=147 Accuracy=75.43:  31%|███       | 145/469 [00:06<00:15, 21.20it/s]\u001b[A\n",
            "Epoch=0 Loss=0.28702956438064575 Batch_id=147 Accuracy=75.43:  32%|███▏      | 148/469 [00:06<00:14, 21.97it/s]\u001b[A\n",
            "Epoch=0 Loss=0.20823533833026886 Batch_id=148 Accuracy=75.58:  32%|███▏      | 148/469 [00:06<00:14, 21.97it/s]\u001b[A\n",
            "Epoch=0 Loss=0.19441360235214233 Batch_id=149 Accuracy=75.72:  32%|███▏      | 148/469 [00:06<00:14, 21.97it/s]\u001b[A\n",
            "Epoch=0 Loss=0.2170490026473999 Batch_id=150 Accuracy=75.86:  32%|███▏      | 148/469 [00:06<00:14, 21.97it/s] \u001b[A\n",
            "Epoch=0 Loss=0.2170490026473999 Batch_id=150 Accuracy=75.86:  32%|███▏      | 151/469 [00:06<00:14, 22.24it/s]\u001b[A\n",
            "Epoch=0 Loss=0.3122199475765228 Batch_id=151 Accuracy=75.97:  32%|███▏      | 151/469 [00:06<00:14, 22.24it/s]\u001b[A\n",
            "Epoch=0 Loss=0.21348243951797485 Batch_id=152 Accuracy=76.10:  32%|███▏      | 151/469 [00:07<00:14, 22.24it/s]\u001b[A\n",
            "Epoch=0 Loss=0.19054241478443146 Batch_id=153 Accuracy=76.25:  32%|███▏      | 151/469 [00:07<00:14, 22.24it/s]\u001b[A\n",
            "Epoch=0 Loss=0.19054241478443146 Batch_id=153 Accuracy=76.25:  33%|███▎      | 154/469 [00:07<00:14, 22.28it/s]\u001b[A\n",
            "Epoch=0 Loss=0.2324552983045578 Batch_id=154 Accuracy=76.38:  33%|███▎      | 154/469 [00:07<00:14, 22.28it/s] \u001b[A\n",
            "Epoch=0 Loss=0.25476276874542236 Batch_id=155 Accuracy=76.47:  33%|███▎      | 154/469 [00:07<00:14, 22.28it/s]\u001b[A\n",
            "Epoch=0 Loss=0.28077077865600586 Batch_id=156 Accuracy=76.57:  33%|███▎      | 154/469 [00:07<00:14, 22.28it/s]\u001b[A\n",
            "Epoch=0 Loss=0.28077077865600586 Batch_id=156 Accuracy=76.57:  33%|███▎      | 157/469 [00:07<00:13, 23.15it/s]\u001b[A\n",
            "Epoch=0 Loss=0.27633869647979736 Batch_id=157 Accuracy=76.69:  33%|███▎      | 157/469 [00:07<00:13, 23.15it/s]\u001b[A\n",
            "Epoch=0 Loss=0.17770425975322723 Batch_id=158 Accuracy=76.83:  33%|███▎      | 157/469 [00:07<00:13, 23.15it/s]\u001b[A\n",
            "Epoch=0 Loss=0.23997052013874054 Batch_id=159 Accuracy=76.95:  33%|███▎      | 157/469 [00:07<00:13, 23.15it/s]\u001b[A\n",
            "Epoch=0 Loss=0.2406766414642334 Batch_id=160 Accuracy=77.07:  33%|███▎      | 157/469 [00:07<00:13, 23.15it/s] \u001b[A\n",
            "Epoch=0 Loss=0.2406766414642334 Batch_id=160 Accuracy=77.07:  34%|███▍      | 161/469 [00:07<00:11, 25.71it/s]\u001b[A\n",
            "Epoch=0 Loss=0.1899968385696411 Batch_id=161 Accuracy=77.19:  34%|███▍      | 161/469 [00:07<00:11, 25.71it/s]\u001b[A\n",
            "Epoch=0 Loss=0.22586284577846527 Batch_id=162 Accuracy=77.30:  34%|███▍      | 161/469 [00:07<00:11, 25.71it/s]\u001b[A\n",
            "Epoch=0 Loss=0.2060045301914215 Batch_id=163 Accuracy=77.42:  34%|███▍      | 161/469 [00:07<00:11, 25.71it/s] \u001b[A\n",
            "Epoch=0 Loss=0.2060045301914215 Batch_id=163 Accuracy=77.42:  35%|███▍      | 164/469 [00:07<00:11, 25.47it/s]\u001b[A\n",
            "Epoch=0 Loss=0.26213768124580383 Batch_id=164 Accuracy=77.52:  35%|███▍      | 164/469 [00:07<00:11, 25.47it/s]\u001b[A\n",
            "Epoch=0 Loss=0.21068565547466278 Batch_id=165 Accuracy=77.64:  35%|███▍      | 164/469 [00:07<00:11, 25.47it/s]\u001b[A\n",
            "Epoch=0 Loss=0.19316592812538147 Batch_id=166 Accuracy=77.75:  35%|███▍      | 164/469 [00:07<00:11, 25.47it/s]\u001b[A\n",
            "Epoch=0 Loss=0.2133570909500122 Batch_id=167 Accuracy=77.87:  35%|███▍      | 164/469 [00:07<00:11, 25.47it/s] \u001b[A\n",
            "Epoch=0 Loss=0.2133570909500122 Batch_id=167 Accuracy=77.87:  36%|███▌      | 168/469 [00:07<00:11, 26.60it/s]\u001b[A\n",
            "Epoch=0 Loss=0.19980205595493317 Batch_id=168 Accuracy=77.98:  36%|███▌      | 168/469 [00:07<00:11, 26.60it/s]\u001b[A\n",
            "Epoch=0 Loss=0.30811378359794617 Batch_id=169 Accuracy=78.06:  36%|███▌      | 168/469 [00:07<00:11, 26.60it/s]\u001b[A\n",
            "Epoch=0 Loss=0.17614935338497162 Batch_id=170 Accuracy=78.18:  36%|███▌      | 168/469 [00:07<00:11, 26.60it/s]\u001b[A\n",
            "Epoch=0 Loss=0.17614935338497162 Batch_id=170 Accuracy=78.18:  36%|███▋      | 171/469 [00:07<00:11, 25.30it/s]\u001b[A\n",
            "Epoch=0 Loss=0.2058209329843521 Batch_id=171 Accuracy=78.28:  36%|███▋      | 171/469 [00:07<00:11, 25.30it/s] \u001b[A\n",
            "Epoch=0 Loss=0.2440619170665741 Batch_id=172 Accuracy=78.37:  36%|███▋      | 171/469 [00:07<00:11, 25.30it/s]\u001b[A\n",
            "Epoch=0 Loss=0.21001079678535461 Batch_id=173 Accuracy=78.48:  36%|███▋      | 171/469 [00:07<00:11, 25.30it/s]\u001b[A\n",
            "Epoch=0 Loss=0.21001079678535461 Batch_id=173 Accuracy=78.48:  37%|███▋      | 174/469 [00:07<00:11, 24.77it/s]\u001b[A\n",
            "Epoch=0 Loss=0.22792617976665497 Batch_id=174 Accuracy=78.57:  37%|███▋      | 174/469 [00:07<00:11, 24.77it/s]\u001b[A\n",
            "Epoch=0 Loss=0.17422515153884888 Batch_id=175 Accuracy=78.68:  37%|███▋      | 174/469 [00:07<00:11, 24.77it/s]\u001b[A\n",
            "Epoch=0 Loss=0.21208976209163666 Batch_id=176 Accuracy=78.78:  37%|███▋      | 174/469 [00:07<00:11, 24.77it/s]\u001b[A\n",
            "Epoch=0 Loss=0.21208976209163666 Batch_id=176 Accuracy=78.78:  38%|███▊      | 177/469 [00:07<00:11, 26.02it/s]\u001b[A\n",
            "Epoch=0 Loss=0.16764716804027557 Batch_id=177 Accuracy=78.89:  38%|███▊      | 177/469 [00:07<00:11, 26.02it/s]\u001b[A\n",
            "Epoch=0 Loss=0.20823200047016144 Batch_id=178 Accuracy=78.98:  38%|███▊      | 177/469 [00:08<00:11, 26.02it/s]\u001b[A\n",
            "Epoch=0 Loss=0.1674615740776062 Batch_id=179 Accuracy=79.08:  38%|███▊      | 177/469 [00:08<00:11, 26.02it/s] \u001b[A\n",
            "Epoch=0 Loss=0.1674615740776062 Batch_id=179 Accuracy=79.08:  38%|███▊      | 180/469 [00:08<00:10, 26.30it/s]\u001b[A\n",
            "Epoch=0 Loss=0.2317347526550293 Batch_id=180 Accuracy=79.17:  38%|███▊      | 180/469 [00:08<00:10, 26.30it/s]\u001b[A\n",
            "Epoch=0 Loss=0.24411889910697937 Batch_id=181 Accuracy=79.26:  38%|███▊      | 180/469 [00:08<00:10, 26.30it/s]\u001b[A\n",
            "Epoch=0 Loss=0.1585923582315445 Batch_id=182 Accuracy=79.36:  38%|███▊      | 180/469 [00:08<00:10, 26.30it/s] \u001b[A\n",
            "Epoch=0 Loss=0.1585923582315445 Batch_id=182 Accuracy=79.36:  39%|███▉      | 183/469 [00:08<00:10, 26.08it/s]\u001b[A\n",
            "Epoch=0 Loss=0.21700510382652283 Batch_id=183 Accuracy=79.46:  39%|███▉      | 183/469 [00:08<00:10, 26.08it/s]\u001b[A\n",
            "Epoch=0 Loss=0.13989165425300598 Batch_id=184 Accuracy=79.57:  39%|███▉      | 183/469 [00:08<00:10, 26.08it/s]\u001b[A\n",
            "Epoch=0 Loss=0.20613300800323486 Batch_id=185 Accuracy=79.65:  39%|███▉      | 183/469 [00:08<00:10, 26.08it/s]\u001b[A\n",
            "Epoch=0 Loss=0.20613300800323486 Batch_id=185 Accuracy=79.65:  40%|███▉      | 186/469 [00:08<00:10, 25.90it/s]\u001b[A\n",
            "Epoch=0 Loss=0.17288480699062347 Batch_id=186 Accuracy=79.75:  40%|███▉      | 186/469 [00:08<00:10, 25.90it/s]\u001b[A\n",
            "Epoch=0 Loss=0.17837171256542206 Batch_id=187 Accuracy=79.83:  40%|███▉      | 186/469 [00:08<00:10, 25.90it/s]\u001b[A\n",
            "Epoch=0 Loss=0.1849125474691391 Batch_id=188 Accuracy=79.92:  40%|███▉      | 186/469 [00:08<00:10, 25.90it/s] \u001b[A\n",
            "Epoch=0 Loss=0.1849125474691391 Batch_id=188 Accuracy=79.92:  40%|████      | 189/469 [00:08<00:10, 26.37it/s]\u001b[A\n",
            "Epoch=0 Loss=0.17113445699214935 Batch_id=189 Accuracy=80.01:  40%|████      | 189/469 [00:08<00:10, 26.37it/s]\u001b[A\n",
            "Epoch=0 Loss=0.1441040188074112 Batch_id=190 Accuracy=80.11:  40%|████      | 189/469 [00:08<00:10, 26.37it/s] \u001b[A\n",
            "Epoch=0 Loss=0.17700150609016418 Batch_id=191 Accuracy=80.19:  40%|████      | 189/469 [00:08<00:10, 26.37it/s]\u001b[A\n",
            "Epoch=0 Loss=0.17700150609016418 Batch_id=191 Accuracy=80.19:  41%|████      | 192/469 [00:08<00:11, 23.34it/s]\u001b[A\n",
            "Epoch=0 Loss=0.21278242766857147 Batch_id=192 Accuracy=80.28:  41%|████      | 192/469 [00:08<00:11, 23.34it/s]\u001b[A\n",
            "Epoch=0 Loss=0.1676270067691803 Batch_id=193 Accuracy=80.37:  41%|████      | 192/469 [00:08<00:11, 23.34it/s] \u001b[A\n",
            "Epoch=0 Loss=0.16367700695991516 Batch_id=194 Accuracy=80.46:  41%|████      | 192/469 [00:08<00:11, 23.34it/s]\u001b[A\n",
            "Epoch=0 Loss=0.16367700695991516 Batch_id=194 Accuracy=80.46:  42%|████▏     | 195/469 [00:08<00:12, 21.51it/s]\u001b[A\n",
            "Epoch=0 Loss=0.17763125896453857 Batch_id=195 Accuracy=80.54:  42%|████▏     | 195/469 [00:08<00:12, 21.51it/s]\u001b[A\n",
            "Epoch=0 Loss=0.2503677010536194 Batch_id=196 Accuracy=80.60:  42%|████▏     | 195/469 [00:08<00:12, 21.51it/s] \u001b[A\n",
            "Epoch=0 Loss=0.1888449639081955 Batch_id=197 Accuracy=80.67:  42%|████▏     | 195/469 [00:08<00:12, 21.51it/s]\u001b[A\n",
            "Epoch=0 Loss=0.1888449639081955 Batch_id=197 Accuracy=80.67:  42%|████▏     | 198/469 [00:08<00:12, 21.03it/s]\u001b[A\n",
            "Epoch=0 Loss=0.18364939093589783 Batch_id=198 Accuracy=80.74:  42%|████▏     | 198/469 [00:08<00:12, 21.03it/s]\u001b[A\n",
            "Epoch=0 Loss=0.18743430078029633 Batch_id=199 Accuracy=80.82:  42%|████▏     | 198/469 [00:08<00:12, 21.03it/s]\u001b[A\n",
            "Epoch=0 Loss=0.220819354057312 Batch_id=200 Accuracy=80.90:  42%|████▏     | 198/469 [00:08<00:12, 21.03it/s]  \u001b[A\n",
            "Epoch=0 Loss=0.220819354057312 Batch_id=200 Accuracy=80.90:  43%|████▎     | 201/469 [00:09<00:12, 21.70it/s]\u001b[A\n",
            "Epoch=0 Loss=0.14600998163223267 Batch_id=201 Accuracy=80.98:  43%|████▎     | 201/469 [00:09<00:12, 21.70it/s]\u001b[A\n",
            "Epoch=0 Loss=0.08635840564966202 Batch_id=202 Accuracy=81.07:  43%|████▎     | 201/469 [00:09<00:12, 21.70it/s]\u001b[A\n",
            "Epoch=0 Loss=0.1495591104030609 Batch_id=203 Accuracy=81.15:  43%|████▎     | 201/469 [00:09<00:12, 21.70it/s] \u001b[A\n",
            "Epoch=0 Loss=0.1495591104030609 Batch_id=203 Accuracy=81.15:  43%|████▎     | 204/469 [00:09<00:12, 22.07it/s]\u001b[A\n",
            "Epoch=0 Loss=0.17123572528362274 Batch_id=204 Accuracy=81.23:  43%|████▎     | 204/469 [00:09<00:12, 22.07it/s]\u001b[A\n",
            "Epoch=0 Loss=0.17050856351852417 Batch_id=205 Accuracy=81.30:  43%|████▎     | 204/469 [00:09<00:12, 22.07it/s]\u001b[A\n",
            "Epoch=0 Loss=0.143607497215271 Batch_id=206 Accuracy=81.37:  43%|████▎     | 204/469 [00:09<00:12, 22.07it/s]  \u001b[A\n",
            "Epoch=0 Loss=0.143607497215271 Batch_id=206 Accuracy=81.37:  44%|████▍     | 207/469 [00:09<00:11, 22.10it/s]\u001b[A\n",
            "Epoch=0 Loss=0.13828709721565247 Batch_id=207 Accuracy=81.45:  44%|████▍     | 207/469 [00:09<00:11, 22.10it/s]\u001b[A\n",
            "Epoch=0 Loss=0.180233433842659 Batch_id=208 Accuracy=81.52:  44%|████▍     | 207/469 [00:09<00:11, 22.10it/s]  \u001b[A\n",
            "Epoch=0 Loss=0.12991051375865936 Batch_id=209 Accuracy=81.60:  44%|████▍     | 207/469 [00:09<00:11, 22.10it/s]\u001b[A\n",
            "Epoch=0 Loss=0.12991051375865936 Batch_id=209 Accuracy=81.60:  45%|████▍     | 210/469 [00:09<00:11, 22.33it/s]\u001b[A\n",
            "Epoch=0 Loss=0.17048466205596924 Batch_id=210 Accuracy=81.68:  45%|████▍     | 210/469 [00:09<00:11, 22.33it/s]\u001b[A\n",
            "Epoch=0 Loss=0.13537728786468506 Batch_id=211 Accuracy=81.76:  45%|████▍     | 210/469 [00:09<00:11, 22.33it/s]\u001b[A\n",
            "Epoch=0 Loss=0.22511281073093414 Batch_id=212 Accuracy=81.81:  45%|████▍     | 210/469 [00:09<00:11, 22.33it/s]\u001b[A\n",
            "Epoch=0 Loss=0.22511281073093414 Batch_id=212 Accuracy=81.81:  45%|████▌     | 213/469 [00:09<00:11, 21.52it/s]\u001b[A\n",
            "Epoch=0 Loss=0.19744354486465454 Batch_id=213 Accuracy=81.87:  45%|████▌     | 213/469 [00:09<00:11, 21.52it/s]\u001b[A\n",
            "Epoch=0 Loss=0.13355867564678192 Batch_id=214 Accuracy=81.94:  45%|████▌     | 213/469 [00:09<00:11, 21.52it/s]\u001b[A\n",
            "Epoch=0 Loss=0.1462661623954773 Batch_id=215 Accuracy=82.01:  45%|████▌     | 213/469 [00:09<00:11, 21.52it/s] \u001b[A\n",
            "Epoch=0 Loss=0.1462661623954773 Batch_id=215 Accuracy=82.01:  46%|████▌     | 216/469 [00:09<00:12, 19.72it/s]\u001b[A\n",
            "Epoch=0 Loss=0.136055588722229 Batch_id=216 Accuracy=82.07:  46%|████▌     | 216/469 [00:09<00:12, 19.72it/s] \u001b[A\n",
            "Epoch=0 Loss=0.11355693638324738 Batch_id=217 Accuracy=82.14:  46%|████▌     | 216/469 [00:09<00:12, 19.72it/s]\u001b[A\n",
            "Epoch=0 Loss=0.12729884684085846 Batch_id=218 Accuracy=82.22:  46%|████▌     | 216/469 [00:09<00:12, 19.72it/s]\u001b[A\n",
            "Epoch=0 Loss=0.12729884684085846 Batch_id=218 Accuracy=82.22:  47%|████▋     | 219/469 [00:09<00:13, 19.10it/s]\u001b[A\n",
            "Epoch=0 Loss=0.18194396793842316 Batch_id=219 Accuracy=82.28:  47%|████▋     | 219/469 [00:09<00:13, 19.10it/s]\u001b[A\n",
            "Epoch=0 Loss=0.13410142064094543 Batch_id=220 Accuracy=82.35:  47%|████▋     | 219/469 [00:09<00:13, 19.10it/s]\u001b[A\n",
            "Epoch=0 Loss=0.2221735566854477 Batch_id=221 Accuracy=82.41:  47%|████▋     | 219/469 [00:10<00:13, 19.10it/s] \u001b[A\n",
            "Epoch=0 Loss=0.2221735566854477 Batch_id=221 Accuracy=82.41:  47%|████▋     | 222/469 [00:10<00:12, 20.03it/s]\u001b[A\n",
            "Epoch=0 Loss=0.14570191502571106 Batch_id=222 Accuracy=82.48:  47%|████▋     | 222/469 [00:10<00:12, 20.03it/s]\u001b[A\n",
            "Epoch=0 Loss=0.1592712104320526 Batch_id=223 Accuracy=82.54:  47%|████▋     | 222/469 [00:10<00:12, 20.03it/s] \u001b[A\n",
            "Epoch=0 Loss=0.16061437129974365 Batch_id=224 Accuracy=82.61:  47%|████▋     | 222/469 [00:10<00:12, 20.03it/s]\u001b[A\n",
            "Epoch=0 Loss=0.16061437129974365 Batch_id=224 Accuracy=82.61:  48%|████▊     | 225/469 [00:10<00:11, 20.45it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11202508211135864 Batch_id=225 Accuracy=82.68:  48%|████▊     | 225/469 [00:10<00:11, 20.45it/s]\u001b[A\n",
            "Epoch=0 Loss=0.10819168388843536 Batch_id=226 Accuracy=82.75:  48%|████▊     | 225/469 [00:10<00:11, 20.45it/s]\u001b[A\n",
            "Epoch=0 Loss=0.21982601284980774 Batch_id=227 Accuracy=82.80:  48%|████▊     | 225/469 [00:10<00:11, 20.45it/s]\u001b[A\n",
            "Epoch=0 Loss=0.21982601284980774 Batch_id=227 Accuracy=82.80:  49%|████▊     | 228/469 [00:10<00:11, 21.22it/s]\u001b[A\n",
            "Epoch=0 Loss=0.15628641843795776 Batch_id=228 Accuracy=82.86:  49%|████▊     | 228/469 [00:10<00:11, 21.22it/s]\u001b[A\n",
            "Epoch=0 Loss=0.20917072892189026 Batch_id=229 Accuracy=82.90:  49%|████▊     | 228/469 [00:10<00:11, 21.22it/s]\u001b[A\n",
            "Epoch=0 Loss=0.16208603978157043 Batch_id=230 Accuracy=82.97:  49%|████▊     | 228/469 [00:10<00:11, 21.22it/s]\u001b[A\n",
            "Epoch=0 Loss=0.16208603978157043 Batch_id=230 Accuracy=82.97:  49%|████▉     | 231/469 [00:10<00:10, 22.21it/s]\u001b[A\n",
            "Epoch=0 Loss=0.16691745817661285 Batch_id=231 Accuracy=83.02:  49%|████▉     | 231/469 [00:10<00:10, 22.21it/s]\u001b[A\n",
            "Epoch=0 Loss=0.14043135941028595 Batch_id=232 Accuracy=83.08:  49%|████▉     | 231/469 [00:10<00:10, 22.21it/s]\u001b[A\n",
            "Epoch=0 Loss=0.16587702929973602 Batch_id=233 Accuracy=83.14:  49%|████▉     | 231/469 [00:10<00:10, 22.21it/s]\u001b[A\n",
            "Epoch=0 Loss=0.16587702929973602 Batch_id=233 Accuracy=83.14:  50%|████▉     | 234/469 [00:10<00:10, 21.71it/s]\u001b[A\n",
            "Epoch=0 Loss=0.10178228467702866 Batch_id=234 Accuracy=83.20:  50%|████▉     | 234/469 [00:10<00:10, 21.71it/s]\u001b[A\n",
            "Epoch=0 Loss=0.17485323548316956 Batch_id=235 Accuracy=83.27:  50%|████▉     | 234/469 [00:10<00:10, 21.71it/s]\u001b[A\n",
            "Epoch=0 Loss=0.14427872002124786 Batch_id=236 Accuracy=83.33:  50%|████▉     | 234/469 [00:10<00:10, 21.71it/s]\u001b[A\n",
            "Epoch=0 Loss=0.14427872002124786 Batch_id=236 Accuracy=83.33:  51%|█████     | 237/469 [00:10<00:09, 23.36it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11133299767971039 Batch_id=237 Accuracy=83.39:  51%|█████     | 237/469 [00:10<00:09, 23.36it/s]\u001b[A\n",
            "Epoch=0 Loss=0.15926766395568848 Batch_id=238 Accuracy=83.44:  51%|█████     | 237/469 [00:10<00:09, 23.36it/s]\u001b[A\n",
            "Epoch=0 Loss=0.13979020714759827 Batch_id=239 Accuracy=83.49:  51%|█████     | 237/469 [00:10<00:09, 23.36it/s]\u001b[A\n",
            "Epoch=0 Loss=0.13979020714759827 Batch_id=239 Accuracy=83.49:  51%|█████     | 240/469 [00:10<00:09, 24.66it/s]\u001b[A\n",
            "Epoch=0 Loss=0.08492527902126312 Batch_id=240 Accuracy=83.56:  51%|█████     | 240/469 [00:10<00:09, 24.66it/s]\u001b[A\n",
            "Epoch=0 Loss=0.14280007779598236 Batch_id=241 Accuracy=83.61:  51%|█████     | 240/469 [00:10<00:09, 24.66it/s]\u001b[A\n",
            "Epoch=0 Loss=0.19268259406089783 Batch_id=242 Accuracy=83.66:  51%|█████     | 240/469 [00:10<00:09, 24.66it/s]\u001b[A\n",
            "Epoch=0 Loss=0.19268259406089783 Batch_id=242 Accuracy=83.66:  52%|█████▏    | 243/469 [00:10<00:11, 20.52it/s]\u001b[A\n",
            "Epoch=0 Loss=0.14516755938529968 Batch_id=243 Accuracy=83.71:  52%|█████▏    | 243/469 [00:11<00:11, 20.52it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11466110497713089 Batch_id=244 Accuracy=83.77:  52%|█████▏    | 243/469 [00:11<00:11, 20.52it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11922348290681839 Batch_id=245 Accuracy=83.82:  52%|█████▏    | 243/469 [00:11<00:11, 20.52it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11922348290681839 Batch_id=245 Accuracy=83.82:  52%|█████▏    | 246/469 [00:11<00:10, 21.00it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11807700991630554 Batch_id=246 Accuracy=83.88:  52%|█████▏    | 246/469 [00:11<00:10, 21.00it/s]\u001b[A\n",
            "Epoch=0 Loss=0.16468840837478638 Batch_id=247 Accuracy=83.92:  52%|█████▏    | 246/469 [00:11<00:10, 21.00it/s]\u001b[A\n",
            "Epoch=0 Loss=0.120912566781044 Batch_id=248 Accuracy=83.98:  52%|█████▏    | 246/469 [00:11<00:10, 21.00it/s]  \u001b[A\n",
            "Epoch=0 Loss=0.120912566781044 Batch_id=248 Accuracy=83.98:  53%|█████▎    | 249/469 [00:11<00:10, 21.25it/s]\u001b[A\n",
            "Epoch=0 Loss=0.12018319964408875 Batch_id=249 Accuracy=84.03:  53%|█████▎    | 249/469 [00:11<00:10, 21.25it/s]\u001b[A\n",
            "Epoch=0 Loss=0.09994195401668549 Batch_id=250 Accuracy=84.09:  53%|█████▎    | 249/469 [00:11<00:10, 21.25it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11781550943851471 Batch_id=251 Accuracy=84.14:  53%|█████▎    | 249/469 [00:11<00:10, 21.25it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11781550943851471 Batch_id=251 Accuracy=84.14:  54%|█████▎    | 252/469 [00:11<00:09, 21.81it/s]\u001b[A\n",
            "Epoch=0 Loss=0.12309527397155762 Batch_id=252 Accuracy=84.20:  54%|█████▎    | 252/469 [00:11<00:09, 21.81it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11312390863895416 Batch_id=253 Accuracy=84.25:  54%|█████▎    | 252/469 [00:11<00:09, 21.81it/s]\u001b[A\n",
            "Epoch=0 Loss=0.09315773099660873 Batch_id=254 Accuracy=84.30:  54%|█████▎    | 252/469 [00:11<00:09, 21.81it/s]\u001b[A\n",
            "Epoch=0 Loss=0.09315773099660873 Batch_id=254 Accuracy=84.30:  54%|█████▍    | 255/469 [00:11<00:09, 21.53it/s]\u001b[A\n",
            "Epoch=0 Loss=0.08096756786108017 Batch_id=255 Accuracy=84.36:  54%|█████▍    | 255/469 [00:11<00:09, 21.53it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11994069069623947 Batch_id=256 Accuracy=84.41:  54%|█████▍    | 255/469 [00:11<00:09, 21.53it/s]\u001b[A\n",
            "Epoch=0 Loss=0.1212429478764534 Batch_id=257 Accuracy=84.46:  54%|█████▍    | 255/469 [00:11<00:09, 21.53it/s] \u001b[A\n",
            "Epoch=0 Loss=0.1212429478764534 Batch_id=257 Accuracy=84.46:  55%|█████▌    | 258/469 [00:11<00:09, 23.26it/s]\u001b[A\n",
            "Epoch=0 Loss=0.16465947031974792 Batch_id=258 Accuracy=84.51:  55%|█████▌    | 258/469 [00:11<00:09, 23.26it/s]\u001b[A\n",
            "Epoch=0 Loss=0.09819769114255905 Batch_id=259 Accuracy=84.56:  55%|█████▌    | 258/469 [00:11<00:09, 23.26it/s]\u001b[A\n",
            "Epoch=0 Loss=0.09996309876441956 Batch_id=260 Accuracy=84.61:  55%|█████▌    | 258/469 [00:11<00:09, 23.26it/s]\u001b[A\n",
            "Epoch=0 Loss=0.09996309876441956 Batch_id=260 Accuracy=84.61:  56%|█████▌    | 261/469 [00:11<00:08, 24.59it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11243507266044617 Batch_id=261 Accuracy=84.67:  56%|█████▌    | 261/469 [00:11<00:08, 24.59it/s]\u001b[A\n",
            "Epoch=0 Loss=0.12342346459627151 Batch_id=262 Accuracy=84.72:  56%|█████▌    | 261/469 [00:11<00:08, 24.59it/s]\u001b[A\n",
            "Epoch=0 Loss=0.20830269157886505 Batch_id=263 Accuracy=84.75:  56%|█████▌    | 261/469 [00:11<00:08, 24.59it/s]\u001b[A\n",
            "Epoch=0 Loss=0.20830269157886505 Batch_id=263 Accuracy=84.75:  56%|█████▋    | 264/469 [00:11<00:08, 23.92it/s]\u001b[A\n",
            "Epoch=0 Loss=0.1690213531255722 Batch_id=264 Accuracy=84.79:  56%|█████▋    | 264/469 [00:11<00:08, 23.92it/s] \u001b[A\n",
            "Epoch=0 Loss=0.12031707167625427 Batch_id=265 Accuracy=84.84:  56%|█████▋    | 264/469 [00:11<00:08, 23.92it/s]\u001b[A\n",
            "Epoch=0 Loss=0.1240072250366211 Batch_id=266 Accuracy=84.89:  56%|█████▋    | 264/469 [00:12<00:08, 23.92it/s] \u001b[A\n",
            "Epoch=0 Loss=0.1240072250366211 Batch_id=266 Accuracy=84.89:  57%|█████▋    | 267/469 [00:12<00:09, 21.26it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11405894160270691 Batch_id=267 Accuracy=84.93:  57%|█████▋    | 267/469 [00:12<00:09, 21.26it/s]\u001b[A\n",
            "Epoch=0 Loss=0.10204910486936569 Batch_id=268 Accuracy=84.99:  57%|█████▋    | 267/469 [00:12<00:09, 21.26it/s]\u001b[A\n",
            "Epoch=0 Loss=0.13579262793064117 Batch_id=269 Accuracy=85.03:  57%|█████▋    | 267/469 [00:12<00:09, 21.26it/s]\u001b[A\n",
            "Epoch=0 Loss=0.13435706496238708 Batch_id=270 Accuracy=85.07:  57%|█████▋    | 267/469 [00:12<00:09, 21.26it/s]\u001b[A\n",
            "Epoch=0 Loss=0.13435706496238708 Batch_id=270 Accuracy=85.07:  58%|█████▊    | 271/469 [00:12<00:08, 23.73it/s]\u001b[A\n",
            "Epoch=0 Loss=0.1148817241191864 Batch_id=271 Accuracy=85.12:  58%|█████▊    | 271/469 [00:12<00:08, 23.73it/s] \u001b[A\n",
            "Epoch=0 Loss=0.14066877961158752 Batch_id=272 Accuracy=85.16:  58%|█████▊    | 271/469 [00:12<00:08, 23.73it/s]\u001b[A\n",
            "Epoch=0 Loss=0.12733528017997742 Batch_id=273 Accuracy=85.20:  58%|█████▊    | 271/469 [00:12<00:08, 23.73it/s]\u001b[A\n",
            "Epoch=0 Loss=0.12733528017997742 Batch_id=273 Accuracy=85.20:  58%|█████▊    | 274/469 [00:12<00:08, 22.82it/s]\u001b[A\n",
            "Epoch=0 Loss=0.13256779313087463 Batch_id=274 Accuracy=85.24:  58%|█████▊    | 274/469 [00:12<00:08, 22.82it/s]\u001b[A\n",
            "Epoch=0 Loss=0.12758740782737732 Batch_id=275 Accuracy=85.28:  58%|█████▊    | 274/469 [00:12<00:08, 22.82it/s]\u001b[A\n",
            "Epoch=0 Loss=0.14355501532554626 Batch_id=276 Accuracy=85.31:  58%|█████▊    | 274/469 [00:12<00:08, 22.82it/s]\u001b[A\n",
            "Epoch=0 Loss=0.14355501532554626 Batch_id=276 Accuracy=85.31:  59%|█████▉    | 277/469 [00:12<00:08, 23.45it/s]\u001b[A\n",
            "Epoch=0 Loss=0.15669620037078857 Batch_id=277 Accuracy=85.36:  59%|█████▉    | 277/469 [00:12<00:08, 23.45it/s]\u001b[A\n",
            "Epoch=0 Loss=0.08838348090648651 Batch_id=278 Accuracy=85.40:  59%|█████▉    | 277/469 [00:12<00:08, 23.45it/s]\u001b[A\n",
            "Epoch=0 Loss=0.1346103847026825 Batch_id=279 Accuracy=85.45:  59%|█████▉    | 277/469 [00:12<00:08, 23.45it/s] \u001b[A\n",
            "Epoch=0 Loss=0.1346103847026825 Batch_id=279 Accuracy=85.45:  60%|█████▉    | 280/469 [00:12<00:07, 23.97it/s]\u001b[A\n",
            "Epoch=0 Loss=0.09217499196529388 Batch_id=280 Accuracy=85.49:  60%|█████▉    | 280/469 [00:12<00:07, 23.97it/s]\u001b[A\n",
            "Epoch=0 Loss=0.18245577812194824 Batch_id=281 Accuracy=85.52:  60%|█████▉    | 280/469 [00:12<00:07, 23.97it/s]\u001b[A\n",
            "Epoch=0 Loss=0.20342440903186798 Batch_id=282 Accuracy=85.56:  60%|█████▉    | 280/469 [00:12<00:07, 23.97it/s]\u001b[A\n",
            "Epoch=0 Loss=0.20342440903186798 Batch_id=282 Accuracy=85.56:  60%|██████    | 283/469 [00:12<00:08, 23.02it/s]\u001b[A\n",
            "Epoch=0 Loss=0.13706497848033905 Batch_id=283 Accuracy=85.60:  60%|██████    | 283/469 [00:12<00:08, 23.02it/s]\u001b[A\n",
            "Epoch=0 Loss=0.14019207656383514 Batch_id=284 Accuracy=85.64:  60%|██████    | 283/469 [00:12<00:08, 23.02it/s]\u001b[A\n",
            "Epoch=0 Loss=0.062033697962760925 Batch_id=285 Accuracy=85.69:  60%|██████    | 283/469 [00:12<00:08, 23.02it/s]\u001b[A\n",
            "Epoch=0 Loss=0.062033697962760925 Batch_id=285 Accuracy=85.69:  61%|██████    | 286/469 [00:12<00:08, 22.07it/s]\u001b[A\n",
            "Epoch=0 Loss=0.1387525200843811 Batch_id=286 Accuracy=85.73:  61%|██████    | 286/469 [00:12<00:08, 22.07it/s]  \u001b[A\n",
            "Epoch=0 Loss=0.1607256382703781 Batch_id=287 Accuracy=85.77:  61%|██████    | 286/469 [00:12<00:08, 22.07it/s]\u001b[A\n",
            "Epoch=0 Loss=0.12346145510673523 Batch_id=288 Accuracy=85.81:  61%|██████    | 286/469 [00:12<00:08, 22.07it/s]\u001b[A\n",
            "Epoch=0 Loss=0.12346145510673523 Batch_id=288 Accuracy=85.81:  62%|██████▏   | 289/469 [00:13<00:08, 20.45it/s]\u001b[A\n",
            "Epoch=0 Loss=0.12969650328159332 Batch_id=289 Accuracy=85.84:  62%|██████▏   | 289/469 [00:13<00:08, 20.45it/s]\u001b[A\n",
            "Epoch=0 Loss=0.1273750364780426 Batch_id=290 Accuracy=85.88:  62%|██████▏   | 289/469 [00:13<00:08, 20.45it/s] \u001b[A\n",
            "Epoch=0 Loss=0.09735511243343353 Batch_id=291 Accuracy=85.92:  62%|██████▏   | 289/469 [00:13<00:08, 20.45it/s]\u001b[A\n",
            "Epoch=0 Loss=0.09735511243343353 Batch_id=291 Accuracy=85.92:  62%|██████▏   | 292/469 [00:13<00:08, 20.12it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11353914439678192 Batch_id=292 Accuracy=85.96:  62%|██████▏   | 292/469 [00:13<00:08, 20.12it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11616203933954239 Batch_id=293 Accuracy=86.01:  62%|██████▏   | 292/469 [00:13<00:08, 20.12it/s]\u001b[A\n",
            "Epoch=0 Loss=0.09778399765491486 Batch_id=294 Accuracy=86.05:  62%|██████▏   | 292/469 [00:13<00:08, 20.12it/s]\u001b[A\n",
            "Epoch=0 Loss=0.09778399765491486 Batch_id=294 Accuracy=86.05:  63%|██████▎   | 295/469 [00:13<00:08, 20.27it/s]\u001b[A\n",
            "Epoch=0 Loss=0.09607291966676712 Batch_id=295 Accuracy=86.10:  63%|██████▎   | 295/469 [00:13<00:08, 20.27it/s]\u001b[A\n",
            "Epoch=0 Loss=0.14276917278766632 Batch_id=296 Accuracy=86.14:  63%|██████▎   | 295/469 [00:13<00:08, 20.27it/s]\u001b[A\n",
            "Epoch=0 Loss=0.1406673640012741 Batch_id=297 Accuracy=86.17:  63%|██████▎   | 295/469 [00:13<00:08, 20.27it/s] \u001b[A\n",
            "Epoch=0 Loss=0.1406673640012741 Batch_id=297 Accuracy=86.17:  64%|██████▎   | 298/469 [00:13<00:08, 20.71it/s]\u001b[A\n",
            "Epoch=0 Loss=0.10876278579235077 Batch_id=298 Accuracy=86.21:  64%|██████▎   | 298/469 [00:13<00:08, 20.71it/s]\u001b[A\n",
            "Epoch=0 Loss=0.1640070676803589 Batch_id=299 Accuracy=86.25:  64%|██████▎   | 298/469 [00:13<00:08, 20.71it/s] \u001b[A\n",
            "Epoch=0 Loss=0.13175475597381592 Batch_id=300 Accuracy=86.28:  64%|██████▎   | 298/469 [00:13<00:08, 20.71it/s]\u001b[A\n",
            "Epoch=0 Loss=0.13175475597381592 Batch_id=300 Accuracy=86.28:  64%|██████▍   | 301/469 [00:13<00:07, 21.91it/s]\u001b[A\n",
            "Epoch=0 Loss=0.12326972186565399 Batch_id=301 Accuracy=86.32:  64%|██████▍   | 301/469 [00:13<00:07, 21.91it/s]\u001b[A\n",
            "Epoch=0 Loss=0.17929130792617798 Batch_id=302 Accuracy=86.35:  64%|██████▍   | 301/469 [00:13<00:07, 21.91it/s]\u001b[A\n",
            "Epoch=0 Loss=0.13943982124328613 Batch_id=303 Accuracy=86.38:  64%|██████▍   | 301/469 [00:13<00:07, 21.91it/s]\u001b[A\n",
            "Epoch=0 Loss=0.13943982124328613 Batch_id=303 Accuracy=86.38:  65%|██████▍   | 304/469 [00:13<00:07, 21.71it/s]\u001b[A\n",
            "Epoch=0 Loss=0.10889007151126862 Batch_id=304 Accuracy=86.42:  65%|██████▍   | 304/469 [00:13<00:07, 21.71it/s]\u001b[A\n",
            "Epoch=0 Loss=0.112214595079422 Batch_id=305 Accuracy=86.46:  65%|██████▍   | 304/469 [00:13<00:07, 21.71it/s]  \u001b[A\n",
            "Epoch=0 Loss=0.10909289121627808 Batch_id=306 Accuracy=86.49:  65%|██████▍   | 304/469 [00:13<00:07, 21.71it/s]\u001b[A\n",
            "Epoch=0 Loss=0.10909289121627808 Batch_id=306 Accuracy=86.49:  65%|██████▌   | 307/469 [00:13<00:07, 21.61it/s]\u001b[A\n",
            "Epoch=0 Loss=0.12740077078342438 Batch_id=307 Accuracy=86.52:  65%|██████▌   | 307/469 [00:13<00:07, 21.61it/s]\u001b[A\n",
            "Epoch=0 Loss=0.13568414747714996 Batch_id=308 Accuracy=86.56:  65%|██████▌   | 307/469 [00:13<00:07, 21.61it/s]\u001b[A\n",
            "Epoch=0 Loss=0.07982902973890305 Batch_id=309 Accuracy=86.60:  65%|██████▌   | 307/469 [00:13<00:07, 21.61it/s]\u001b[A\n",
            "Epoch=0 Loss=0.07982902973890305 Batch_id=309 Accuracy=86.60:  66%|██████▌   | 310/469 [00:14<00:07, 20.88it/s]\u001b[A\n",
            "Epoch=0 Loss=0.06314706802368164 Batch_id=310 Accuracy=86.64:  66%|██████▌   | 310/469 [00:14<00:07, 20.88it/s]\u001b[A\n",
            "Epoch=0 Loss=0.12220358103513718 Batch_id=311 Accuracy=86.67:  66%|██████▌   | 310/469 [00:14<00:07, 20.88it/s]\u001b[A\n",
            "Epoch=0 Loss=0.10177505761384964 Batch_id=312 Accuracy=86.70:  66%|██████▌   | 310/469 [00:14<00:07, 20.88it/s]\u001b[A\n",
            "Epoch=0 Loss=0.10177505761384964 Batch_id=312 Accuracy=86.70:  67%|██████▋   | 313/469 [00:14<00:07, 21.30it/s]\u001b[A\n",
            "Epoch=0 Loss=0.09024403244256973 Batch_id=313 Accuracy=86.74:  67%|██████▋   | 313/469 [00:14<00:07, 21.30it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11928008496761322 Batch_id=314 Accuracy=86.77:  67%|██████▋   | 313/469 [00:14<00:07, 21.30it/s]\u001b[A\n",
            "Epoch=0 Loss=0.1417214274406433 Batch_id=315 Accuracy=86.81:  67%|██████▋   | 313/469 [00:14<00:07, 21.30it/s] \u001b[A\n",
            "Epoch=0 Loss=0.1417214274406433 Batch_id=315 Accuracy=86.81:  67%|██████▋   | 316/469 [00:14<00:06, 22.32it/s]\u001b[A\n",
            "Epoch=0 Loss=0.1036175787448883 Batch_id=316 Accuracy=86.84:  67%|██████▋   | 316/469 [00:14<00:06, 22.32it/s]\u001b[A\n",
            "Epoch=0 Loss=0.06198110803961754 Batch_id=317 Accuracy=86.88:  67%|██████▋   | 316/469 [00:14<00:06, 22.32it/s]\u001b[A\n",
            "Epoch=0 Loss=0.10455746203660965 Batch_id=318 Accuracy=86.91:  67%|██████▋   | 316/469 [00:14<00:06, 22.32it/s]\u001b[A\n",
            "Epoch=0 Loss=0.10455746203660965 Batch_id=318 Accuracy=86.91:  68%|██████▊   | 319/469 [00:14<00:06, 23.43it/s]\u001b[A\n",
            "Epoch=0 Loss=0.0861571878194809 Batch_id=319 Accuracy=86.95:  68%|██████▊   | 319/469 [00:14<00:06, 23.43it/s] \u001b[A\n",
            "Epoch=0 Loss=0.07229740917682648 Batch_id=320 Accuracy=86.99:  68%|██████▊   | 319/469 [00:14<00:06, 23.43it/s]\u001b[A\n",
            "Epoch=0 Loss=0.12815064191818237 Batch_id=321 Accuracy=87.01:  68%|██████▊   | 319/469 [00:14<00:06, 23.43it/s]\u001b[A\n",
            "Epoch=0 Loss=0.12815064191818237 Batch_id=321 Accuracy=87.01:  69%|██████▊   | 322/469 [00:14<00:06, 23.50it/s]\u001b[A\n",
            "Epoch=0 Loss=0.10339417308568954 Batch_id=322 Accuracy=87.05:  69%|██████▊   | 322/469 [00:14<00:06, 23.50it/s]\u001b[A\n",
            "Epoch=0 Loss=0.09592555463314056 Batch_id=323 Accuracy=87.08:  69%|██████▊   | 322/469 [00:14<00:06, 23.50it/s]\u001b[A\n",
            "Epoch=0 Loss=0.1037006676197052 Batch_id=324 Accuracy=87.11:  69%|██████▊   | 322/469 [00:14<00:06, 23.50it/s] \u001b[A\n",
            "Epoch=0 Loss=0.1037006676197052 Batch_id=324 Accuracy=87.11:  69%|██████▉   | 325/469 [00:14<00:05, 24.59it/s]\u001b[A\n",
            "Epoch=0 Loss=0.07505100965499878 Batch_id=325 Accuracy=87.15:  69%|██████▉   | 325/469 [00:14<00:05, 24.59it/s]\u001b[A\n",
            "Epoch=0 Loss=0.0924936830997467 Batch_id=326 Accuracy=87.18:  69%|██████▉   | 325/469 [00:14<00:05, 24.59it/s] \u001b[A\n",
            "Epoch=0 Loss=0.11929568648338318 Batch_id=327 Accuracy=87.21:  69%|██████▉   | 325/469 [00:14<00:05, 24.59it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11929568648338318 Batch_id=327 Accuracy=87.21:  70%|██████▉   | 328/469 [00:14<00:05, 24.72it/s]\u001b[A\n",
            "Epoch=0 Loss=0.059355128556489944 Batch_id=328 Accuracy=87.24:  70%|██████▉   | 328/469 [00:14<00:05, 24.72it/s]\u001b[A\n",
            "Epoch=0 Loss=0.09864386171102524 Batch_id=329 Accuracy=87.27:  70%|██████▉   | 328/469 [00:14<00:05, 24.72it/s] \u001b[A\n",
            "Epoch=0 Loss=0.0647875964641571 Batch_id=330 Accuracy=87.30:  70%|██████▉   | 328/469 [00:14<00:05, 24.72it/s] \u001b[A\n",
            "Epoch=0 Loss=0.0647875964641571 Batch_id=330 Accuracy=87.30:  71%|███████   | 331/469 [00:14<00:05, 23.43it/s]\u001b[A\n",
            "Epoch=0 Loss=0.18358933925628662 Batch_id=331 Accuracy=87.33:  71%|███████   | 331/469 [00:14<00:05, 23.43it/s]\u001b[A\n",
            "Epoch=0 Loss=0.14057505130767822 Batch_id=332 Accuracy=87.35:  71%|███████   | 331/469 [00:14<00:05, 23.43it/s]\u001b[A\n",
            "Epoch=0 Loss=0.14279122650623322 Batch_id=333 Accuracy=87.38:  71%|███████   | 331/469 [00:15<00:05, 23.43it/s]\u001b[A\n",
            "Epoch=0 Loss=0.14279122650623322 Batch_id=333 Accuracy=87.38:  71%|███████   | 334/469 [00:15<00:06, 21.05it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11925672739744186 Batch_id=334 Accuracy=87.40:  71%|███████   | 334/469 [00:15<00:06, 21.05it/s]\u001b[A\n",
            "Epoch=0 Loss=0.15491385757923126 Batch_id=335 Accuracy=87.43:  71%|███████   | 334/469 [00:15<00:06, 21.05it/s]\u001b[A\n",
            "Epoch=0 Loss=0.07254733145236969 Batch_id=336 Accuracy=87.46:  71%|███████   | 334/469 [00:15<00:06, 21.05it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11191888153553009 Batch_id=337 Accuracy=87.49:  71%|███████   | 334/469 [00:15<00:06, 21.05it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11191888153553009 Batch_id=337 Accuracy=87.49:  72%|███████▏  | 338/469 [00:15<00:05, 23.16it/s]\u001b[A\n",
            "Epoch=0 Loss=0.08151587098836899 Batch_id=338 Accuracy=87.52:  72%|███████▏  | 338/469 [00:15<00:05, 23.16it/s]\u001b[A\n",
            "Epoch=0 Loss=0.10318021476268768 Batch_id=339 Accuracy=87.55:  72%|███████▏  | 338/469 [00:15<00:05, 23.16it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11692549288272858 Batch_id=340 Accuracy=87.57:  72%|███████▏  | 338/469 [00:15<00:05, 23.16it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11692549288272858 Batch_id=340 Accuracy=87.57:  73%|███████▎  | 341/469 [00:15<00:05, 24.02it/s]\u001b[A\n",
            "Epoch=0 Loss=0.09054277092218399 Batch_id=341 Accuracy=87.61:  73%|███████▎  | 341/469 [00:15<00:05, 24.02it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11277594417333603 Batch_id=342 Accuracy=87.63:  73%|███████▎  | 341/469 [00:15<00:05, 24.02it/s]\u001b[A\n",
            "Epoch=0 Loss=0.1631414294242859 Batch_id=343 Accuracy=87.66:  73%|███████▎  | 341/469 [00:15<00:05, 24.02it/s] \u001b[A\n",
            "Epoch=0 Loss=0.1631414294242859 Batch_id=343 Accuracy=87.66:  73%|███████▎  | 344/469 [00:15<00:05, 24.73it/s]\u001b[A\n",
            "Epoch=0 Loss=0.1502174437046051 Batch_id=344 Accuracy=87.68:  73%|███████▎  | 344/469 [00:15<00:05, 24.73it/s]\u001b[A\n",
            "Epoch=0 Loss=0.07133256644010544 Batch_id=345 Accuracy=87.71:  73%|███████▎  | 344/469 [00:15<00:05, 24.73it/s]\u001b[A\n",
            "Epoch=0 Loss=0.10581672191619873 Batch_id=346 Accuracy=87.74:  73%|███████▎  | 344/469 [00:15<00:05, 24.73it/s]\u001b[A\n",
            "Epoch=0 Loss=0.10581672191619873 Batch_id=346 Accuracy=87.74:  74%|███████▍  | 347/469 [00:15<00:04, 25.73it/s]\u001b[A\n",
            "Epoch=0 Loss=0.09593118727207184 Batch_id=347 Accuracy=87.77:  74%|███████▍  | 347/469 [00:15<00:04, 25.73it/s]\u001b[A\n",
            "Epoch=0 Loss=0.07329599559307098 Batch_id=348 Accuracy=87.80:  74%|███████▍  | 347/469 [00:15<00:04, 25.73it/s]\u001b[A\n",
            "Epoch=0 Loss=0.15694120526313782 Batch_id=349 Accuracy=87.83:  74%|███████▍  | 347/469 [00:15<00:04, 25.73it/s]\u001b[A\n",
            "Epoch=0 Loss=0.15694120526313782 Batch_id=349 Accuracy=87.83:  75%|███████▍  | 350/469 [00:15<00:04, 25.02it/s]\u001b[A\n",
            "Epoch=0 Loss=0.09316956251859665 Batch_id=350 Accuracy=87.86:  75%|███████▍  | 350/469 [00:15<00:04, 25.02it/s]\u001b[A\n",
            "Epoch=0 Loss=0.1210731714963913 Batch_id=351 Accuracy=87.89:  75%|███████▍  | 350/469 [00:15<00:04, 25.02it/s] \u001b[A\n",
            "Epoch=0 Loss=0.13043662905693054 Batch_id=352 Accuracy=87.91:  75%|███████▍  | 350/469 [00:15<00:04, 25.02it/s]\u001b[A\n",
            "Epoch=0 Loss=0.13043662905693054 Batch_id=352 Accuracy=87.91:  75%|███████▌  | 353/469 [00:15<00:04, 25.67it/s]\u001b[A\n",
            "Epoch=0 Loss=0.15700563788414001 Batch_id=353 Accuracy=87.93:  75%|███████▌  | 353/469 [00:15<00:04, 25.67it/s]\u001b[A\n",
            "Epoch=0 Loss=0.1067487895488739 Batch_id=354 Accuracy=87.96:  75%|███████▌  | 353/469 [00:15<00:04, 25.67it/s] \u001b[A\n",
            "Epoch=0 Loss=0.05297118052840233 Batch_id=355 Accuracy=87.99:  75%|███████▌  | 353/469 [00:15<00:04, 25.67it/s]\u001b[A\n",
            "Epoch=0 Loss=0.05297118052840233 Batch_id=355 Accuracy=87.99:  76%|███████▌  | 356/469 [00:15<00:04, 25.54it/s]\u001b[A\n",
            "Epoch=0 Loss=0.06963817775249481 Batch_id=356 Accuracy=88.02:  76%|███████▌  | 356/469 [00:15<00:04, 25.54it/s]\u001b[A\n",
            "Epoch=0 Loss=0.12089958786964417 Batch_id=357 Accuracy=88.05:  76%|███████▌  | 356/469 [00:15<00:04, 25.54it/s]\u001b[A\n",
            "Epoch=0 Loss=0.06958025693893433 Batch_id=358 Accuracy=88.07:  76%|███████▌  | 356/469 [00:15<00:04, 25.54it/s]\u001b[A\n",
            "Epoch=0 Loss=0.06958025693893433 Batch_id=358 Accuracy=88.07:  77%|███████▋  | 359/469 [00:15<00:04, 24.80it/s]\u001b[A\n",
            "Epoch=0 Loss=0.15898847579956055 Batch_id=359 Accuracy=88.10:  77%|███████▋  | 359/469 [00:16<00:04, 24.80it/s]\u001b[A\n",
            "Epoch=0 Loss=0.0927133709192276 Batch_id=360 Accuracy=88.13:  77%|███████▋  | 359/469 [00:16<00:04, 24.80it/s] \u001b[A\n",
            "Epoch=0 Loss=0.09380817413330078 Batch_id=361 Accuracy=88.16:  77%|███████▋  | 359/469 [00:16<00:04, 24.80it/s]\u001b[A\n",
            "Epoch=0 Loss=0.09380817413330078 Batch_id=361 Accuracy=88.16:  77%|███████▋  | 362/469 [00:16<00:04, 24.22it/s]\u001b[A\n",
            "Epoch=0 Loss=0.0951462835073471 Batch_id=362 Accuracy=88.18:  77%|███████▋  | 362/469 [00:16<00:04, 24.22it/s] \u001b[A\n",
            "Epoch=0 Loss=0.07125689089298248 Batch_id=363 Accuracy=88.21:  77%|███████▋  | 362/469 [00:16<00:04, 24.22it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11427254229784012 Batch_id=364 Accuracy=88.24:  77%|███████▋  | 362/469 [00:16<00:04, 24.22it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11427254229784012 Batch_id=364 Accuracy=88.24:  78%|███████▊  | 365/469 [00:16<00:04, 24.42it/s]\u001b[A\n",
            "Epoch=0 Loss=0.08085683733224869 Batch_id=365 Accuracy=88.27:  78%|███████▊  | 365/469 [00:16<00:04, 24.42it/s]\u001b[A\n",
            "Epoch=0 Loss=0.07802367955446243 Batch_id=366 Accuracy=88.29:  78%|███████▊  | 365/469 [00:16<00:04, 24.42it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11351428925991058 Batch_id=367 Accuracy=88.32:  78%|███████▊  | 365/469 [00:16<00:04, 24.42it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11351428925991058 Batch_id=367 Accuracy=88.32:  78%|███████▊  | 368/469 [00:16<00:04, 24.96it/s]\u001b[A\n",
            "Epoch=0 Loss=0.09691724926233292 Batch_id=368 Accuracy=88.34:  78%|███████▊  | 368/469 [00:16<00:04, 24.96it/s]\u001b[A\n",
            "Epoch=0 Loss=0.07954162359237671 Batch_id=369 Accuracy=88.37:  78%|███████▊  | 368/469 [00:16<00:04, 24.96it/s]\u001b[A\n",
            "Epoch=0 Loss=0.06113019213080406 Batch_id=370 Accuracy=88.40:  78%|███████▊  | 368/469 [00:16<00:04, 24.96it/s]\u001b[A\n",
            "Epoch=0 Loss=0.06113019213080406 Batch_id=370 Accuracy=88.40:  79%|███████▉  | 371/469 [00:16<00:03, 25.07it/s]\u001b[A\n",
            "Epoch=0 Loss=0.0753876194357872 Batch_id=371 Accuracy=88.43:  79%|███████▉  | 371/469 [00:16<00:03, 25.07it/s] \u001b[A\n",
            "Epoch=0 Loss=0.12748396396636963 Batch_id=372 Accuracy=88.45:  79%|███████▉  | 371/469 [00:16<00:03, 25.07it/s]\u001b[A\n",
            "Epoch=0 Loss=0.12957914173603058 Batch_id=373 Accuracy=88.47:  79%|███████▉  | 371/469 [00:16<00:03, 25.07it/s]\u001b[A\n",
            "Epoch=0 Loss=0.12957914173603058 Batch_id=373 Accuracy=88.47:  80%|███████▉  | 374/469 [00:16<00:03, 25.14it/s]\u001b[A\n",
            "Epoch=0 Loss=0.12486856430768967 Batch_id=374 Accuracy=88.50:  80%|███████▉  | 374/469 [00:16<00:03, 25.14it/s]\u001b[A\n",
            "Epoch=0 Loss=0.07693342864513397 Batch_id=375 Accuracy=88.53:  80%|███████▉  | 374/469 [00:16<00:03, 25.14it/s]\u001b[A\n",
            "Epoch=0 Loss=0.07888340204954147 Batch_id=376 Accuracy=88.55:  80%|███████▉  | 374/469 [00:16<00:03, 25.14it/s]\u001b[A\n",
            "Epoch=0 Loss=0.07888340204954147 Batch_id=376 Accuracy=88.55:  80%|████████  | 377/469 [00:16<00:03, 25.85it/s]\u001b[A\n",
            "Epoch=0 Loss=0.0606534481048584 Batch_id=377 Accuracy=88.58:  80%|████████  | 377/469 [00:16<00:03, 25.85it/s] \u001b[A\n",
            "Epoch=0 Loss=0.11758635938167572 Batch_id=378 Accuracy=88.60:  80%|████████  | 377/469 [00:16<00:03, 25.85it/s]\u001b[A\n",
            "Epoch=0 Loss=0.06382623314857483 Batch_id=379 Accuracy=88.63:  80%|████████  | 377/469 [00:16<00:03, 25.85it/s]\u001b[A\n",
            "Epoch=0 Loss=0.06382623314857483 Batch_id=379 Accuracy=88.63:  81%|████████  | 380/469 [00:16<00:03, 25.49it/s]\u001b[A\n",
            "Epoch=0 Loss=0.10005265474319458 Batch_id=380 Accuracy=88.65:  81%|████████  | 380/469 [00:16<00:03, 25.49it/s]\u001b[A\n",
            "Epoch=0 Loss=0.07623815536499023 Batch_id=381 Accuracy=88.68:  81%|████████  | 380/469 [00:16<00:03, 25.49it/s]\u001b[A\n",
            "Epoch=0 Loss=0.1082204282283783 Batch_id=382 Accuracy=88.69:  81%|████████  | 380/469 [00:16<00:03, 25.49it/s] \u001b[A\n",
            "Epoch=0 Loss=0.1082204282283783 Batch_id=382 Accuracy=88.69:  82%|████████▏ | 383/469 [00:16<00:03, 24.13it/s]\u001b[A\n",
            "Epoch=0 Loss=0.10167964547872543 Batch_id=383 Accuracy=88.72:  82%|████████▏ | 383/469 [00:17<00:03, 24.13it/s]\u001b[A\n",
            "Epoch=0 Loss=0.12207570672035217 Batch_id=384 Accuracy=88.74:  82%|████████▏ | 383/469 [00:17<00:03, 24.13it/s]\u001b[A\n",
            "Epoch=0 Loss=0.1004779040813446 Batch_id=385 Accuracy=88.76:  82%|████████▏ | 383/469 [00:17<00:03, 24.13it/s] \u001b[A\n",
            "Epoch=0 Loss=0.1004779040813446 Batch_id=385 Accuracy=88.76:  82%|████████▏ | 386/469 [00:17<00:03, 22.96it/s]\u001b[A\n",
            "Epoch=0 Loss=0.13961993157863617 Batch_id=386 Accuracy=88.78:  82%|████████▏ | 386/469 [00:17<00:03, 22.96it/s]\u001b[A\n",
            "Epoch=0 Loss=0.06430941820144653 Batch_id=387 Accuracy=88.81:  82%|████████▏ | 386/469 [00:17<00:03, 22.96it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11905694752931595 Batch_id=388 Accuracy=88.83:  82%|████████▏ | 386/469 [00:17<00:03, 22.96it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11905694752931595 Batch_id=388 Accuracy=88.83:  83%|████████▎ | 389/469 [00:17<00:03, 22.08it/s]\u001b[A\n",
            "Epoch=0 Loss=0.10165782272815704 Batch_id=389 Accuracy=88.85:  83%|████████▎ | 389/469 [00:17<00:03, 22.08it/s]\u001b[A\n",
            "Epoch=0 Loss=0.10386812686920166 Batch_id=390 Accuracy=88.87:  83%|████████▎ | 389/469 [00:17<00:03, 22.08it/s]\u001b[A\n",
            "Epoch=0 Loss=0.08859564363956451 Batch_id=391 Accuracy=88.89:  83%|████████▎ | 389/469 [00:17<00:03, 22.08it/s]\u001b[A\n",
            "Epoch=0 Loss=0.08859564363956451 Batch_id=391 Accuracy=88.89:  84%|████████▎ | 392/469 [00:17<00:03, 22.38it/s]\u001b[A\n",
            "Epoch=0 Loss=0.0619368739426136 Batch_id=392 Accuracy=88.92:  84%|████████▎ | 392/469 [00:17<00:03, 22.38it/s] \u001b[A\n",
            "Epoch=0 Loss=0.10322195291519165 Batch_id=393 Accuracy=88.94:  84%|████████▎ | 392/469 [00:17<00:03, 22.38it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11460137367248535 Batch_id=394 Accuracy=88.96:  84%|████████▎ | 392/469 [00:17<00:03, 22.38it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11460137367248535 Batch_id=394 Accuracy=88.96:  84%|████████▍ | 395/469 [00:17<00:03, 23.09it/s]\u001b[A\n",
            "Epoch=0 Loss=0.10358613729476929 Batch_id=395 Accuracy=88.98:  84%|████████▍ | 395/469 [00:17<00:03, 23.09it/s]\u001b[A\n",
            "Epoch=0 Loss=0.0383724719285965 Batch_id=396 Accuracy=89.00:  84%|████████▍ | 395/469 [00:17<00:03, 23.09it/s] \u001b[A\n",
            "Epoch=0 Loss=0.1956009864807129 Batch_id=397 Accuracy=89.02:  84%|████████▍ | 395/469 [00:17<00:03, 23.09it/s]\u001b[A\n",
            "Epoch=0 Loss=0.1956009864807129 Batch_id=397 Accuracy=89.02:  85%|████████▍ | 398/469 [00:17<00:03, 23.54it/s]\u001b[A\n",
            "Epoch=0 Loss=0.06583031266927719 Batch_id=398 Accuracy=89.04:  85%|████████▍ | 398/469 [00:17<00:03, 23.54it/s]\u001b[A\n",
            "Epoch=0 Loss=0.062400251626968384 Batch_id=399 Accuracy=89.07:  85%|████████▍ | 398/469 [00:17<00:03, 23.54it/s]\u001b[A\n",
            "Epoch=0 Loss=0.09499415010213852 Batch_id=400 Accuracy=89.09:  85%|████████▍ | 398/469 [00:17<00:03, 23.54it/s] \u001b[A\n",
            "Epoch=0 Loss=0.09499415010213852 Batch_id=400 Accuracy=89.09:  86%|████████▌ | 401/469 [00:17<00:02, 23.09it/s]\u001b[A\n",
            "Epoch=0 Loss=0.252390593290329 Batch_id=401 Accuracy=89.10:  86%|████████▌ | 401/469 [00:17<00:02, 23.09it/s]  \u001b[A\n",
            "Epoch=0 Loss=0.09827113151550293 Batch_id=402 Accuracy=89.12:  86%|████████▌ | 401/469 [00:17<00:02, 23.09it/s]\u001b[A\n",
            "Epoch=0 Loss=0.09578607976436615 Batch_id=403 Accuracy=89.15:  86%|████████▌ | 401/469 [00:17<00:02, 23.09it/s]\u001b[A\n",
            "Epoch=0 Loss=0.09578607976436615 Batch_id=403 Accuracy=89.15:  86%|████████▌ | 404/469 [00:17<00:02, 23.25it/s]\u001b[A\n",
            "Epoch=0 Loss=0.10743860900402069 Batch_id=404 Accuracy=89.16:  86%|████████▌ | 404/469 [00:17<00:02, 23.25it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11023010313510895 Batch_id=405 Accuracy=89.18:  86%|████████▌ | 404/469 [00:17<00:02, 23.25it/s]\u001b[A\n",
            "Epoch=0 Loss=0.0932752788066864 Batch_id=406 Accuracy=89.21:  86%|████████▌ | 404/469 [00:18<00:02, 23.25it/s] \u001b[A\n",
            "Epoch=0 Loss=0.0932752788066864 Batch_id=406 Accuracy=89.21:  87%|████████▋ | 407/469 [00:18<00:02, 23.52it/s]\u001b[A\n",
            "Epoch=0 Loss=0.15738993883132935 Batch_id=407 Accuracy=89.22:  87%|████████▋ | 407/469 [00:18<00:02, 23.52it/s]\u001b[A\n",
            "Epoch=0 Loss=0.07548484206199646 Batch_id=408 Accuracy=89.24:  87%|████████▋ | 407/469 [00:18<00:02, 23.52it/s]\u001b[A\n",
            "Epoch=0 Loss=0.10829941928386688 Batch_id=409 Accuracy=89.26:  87%|████████▋ | 407/469 [00:18<00:02, 23.52it/s]\u001b[A\n",
            "Epoch=0 Loss=0.10829941928386688 Batch_id=409 Accuracy=89.26:  87%|████████▋ | 410/469 [00:18<00:02, 23.29it/s]\u001b[A\n",
            "Epoch=0 Loss=0.06855156272649765 Batch_id=410 Accuracy=89.29:  87%|████████▋ | 410/469 [00:18<00:02, 23.29it/s]\u001b[A\n",
            "Epoch=0 Loss=0.09526057541370392 Batch_id=411 Accuracy=89.31:  87%|████████▋ | 410/469 [00:18<00:02, 23.29it/s]\u001b[A\n",
            "Epoch=0 Loss=0.09778089821338654 Batch_id=412 Accuracy=89.33:  87%|████████▋ | 410/469 [00:18<00:02, 23.29it/s]\u001b[A\n",
            "Epoch=0 Loss=0.09778089821338654 Batch_id=412 Accuracy=89.33:  88%|████████▊ | 413/469 [00:18<00:02, 23.47it/s]\u001b[A\n",
            "Epoch=0 Loss=0.07044823467731476 Batch_id=413 Accuracy=89.35:  88%|████████▊ | 413/469 [00:18<00:02, 23.47it/s]\u001b[A\n",
            "Epoch=0 Loss=0.13975059986114502 Batch_id=414 Accuracy=89.37:  88%|████████▊ | 413/469 [00:18<00:02, 23.47it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11869412660598755 Batch_id=415 Accuracy=89.39:  88%|████████▊ | 413/469 [00:18<00:02, 23.47it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11869412660598755 Batch_id=415 Accuracy=89.39:  89%|████████▊ | 416/469 [00:18<00:02, 24.59it/s]\u001b[A\n",
            "Epoch=0 Loss=0.1721182018518448 Batch_id=416 Accuracy=89.40:  89%|████████▊ | 416/469 [00:18<00:02, 24.59it/s] \u001b[A\n",
            "Epoch=0 Loss=0.07533466070890427 Batch_id=417 Accuracy=89.42:  89%|████████▊ | 416/469 [00:18<00:02, 24.59it/s]\u001b[A\n",
            "Epoch=0 Loss=0.05272822082042694 Batch_id=418 Accuracy=89.44:  89%|████████▊ | 416/469 [00:18<00:02, 24.59it/s]\u001b[A\n",
            "Epoch=0 Loss=0.05272822082042694 Batch_id=418 Accuracy=89.44:  89%|████████▉ | 419/469 [00:18<00:01, 25.04it/s]\u001b[A\n",
            "Epoch=0 Loss=0.05439965799450874 Batch_id=419 Accuracy=89.47:  89%|████████▉ | 419/469 [00:18<00:01, 25.04it/s]\u001b[A\n",
            "Epoch=0 Loss=0.0917619988322258 Batch_id=420 Accuracy=89.49:  89%|████████▉ | 419/469 [00:18<00:01, 25.04it/s] \u001b[A\n",
            "Epoch=0 Loss=0.08433914184570312 Batch_id=421 Accuracy=89.51:  89%|████████▉ | 419/469 [00:18<00:01, 25.04it/s]\u001b[A\n",
            "Epoch=0 Loss=0.08433914184570312 Batch_id=421 Accuracy=89.51:  90%|████████▉ | 422/469 [00:18<00:01, 25.75it/s]\u001b[A\n",
            "Epoch=0 Loss=0.1809348165988922 Batch_id=422 Accuracy=89.52:  90%|████████▉ | 422/469 [00:18<00:01, 25.75it/s] \u001b[A\n",
            "Epoch=0 Loss=0.08205768465995789 Batch_id=423 Accuracy=89.54:  90%|████████▉ | 422/469 [00:18<00:01, 25.75it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11075492203235626 Batch_id=424 Accuracy=89.56:  90%|████████▉ | 422/469 [00:18<00:01, 25.75it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11075492203235626 Batch_id=424 Accuracy=89.56:  91%|█████████ | 425/469 [00:18<00:01, 26.16it/s]\u001b[A\n",
            "Epoch=0 Loss=0.143720805644989 Batch_id=425 Accuracy=89.57:  91%|█████████ | 425/469 [00:18<00:01, 26.16it/s]  \u001b[A\n",
            "Epoch=0 Loss=0.1677825003862381 Batch_id=426 Accuracy=89.59:  91%|█████████ | 425/469 [00:18<00:01, 26.16it/s]\u001b[A\n",
            "Epoch=0 Loss=0.09167464077472687 Batch_id=427 Accuracy=89.61:  91%|█████████ | 425/469 [00:18<00:01, 26.16it/s]\u001b[A\n",
            "Epoch=0 Loss=0.09167464077472687 Batch_id=427 Accuracy=89.61:  91%|█████████▏| 428/469 [00:18<00:01, 26.16it/s]\u001b[A\n",
            "Epoch=0 Loss=0.11536267399787903 Batch_id=428 Accuracy=89.63:  91%|█████████▏| 428/469 [00:18<00:01, 26.16it/s]\u001b[A\n",
            "Epoch=0 Loss=0.07444795966148376 Batch_id=429 Accuracy=89.65:  91%|█████████▏| 428/469 [00:18<00:01, 26.16it/s]\u001b[A\n",
            "Epoch=0 Loss=0.06890156865119934 Batch_id=430 Accuracy=89.67:  91%|█████████▏| 428/469 [00:18<00:01, 26.16it/s]\u001b[A\n",
            "Epoch=0 Loss=0.06890156865119934 Batch_id=430 Accuracy=89.67:  92%|█████████▏| 431/469 [00:18<00:01, 26.32it/s]\u001b[A\n",
            "Epoch=0 Loss=0.07731825113296509 Batch_id=431 Accuracy=89.69:  92%|█████████▏| 431/469 [00:18<00:01, 26.32it/s]\u001b[A\n",
            "Epoch=0 Loss=0.13248389959335327 Batch_id=432 Accuracy=89.70:  92%|█████████▏| 431/469 [00:19<00:01, 26.32it/s]\u001b[A\n",
            "Epoch=0 Loss=0.08469027280807495 Batch_id=433 Accuracy=89.72:  92%|█████████▏| 431/469 [00:19<00:01, 26.32it/s]\u001b[A\n",
            "Epoch=0 Loss=0.08469027280807495 Batch_id=433 Accuracy=89.72:  93%|█████████▎| 434/469 [00:19<00:01, 25.83it/s]\u001b[A\n",
            "Epoch=0 Loss=0.13340024650096893 Batch_id=434 Accuracy=89.73:  93%|█████████▎| 434/469 [00:19<00:01, 25.83it/s]\u001b[A\n",
            "Epoch=0 Loss=0.08371566236019135 Batch_id=435 Accuracy=89.75:  93%|█████████▎| 434/469 [00:19<00:01, 25.83it/s]\u001b[A\n",
            "Epoch=0 Loss=0.07701309025287628 Batch_id=436 Accuracy=89.77:  93%|█████████▎| 434/469 [00:19<00:01, 25.83it/s]\u001b[A\n",
            "Epoch=0 Loss=0.07701309025287628 Batch_id=436 Accuracy=89.77:  93%|█████████▎| 437/469 [00:19<00:01, 23.96it/s]\u001b[A\n",
            "Epoch=0 Loss=0.14450791478157043 Batch_id=437 Accuracy=89.79:  93%|█████████▎| 437/469 [00:19<00:01, 23.96it/s]\u001b[A\n",
            "Epoch=0 Loss=0.07807403802871704 Batch_id=438 Accuracy=89.81:  93%|█████████▎| 437/469 [00:19<00:01, 23.96it/s]\u001b[A\n",
            "Epoch=0 Loss=0.08306577801704407 Batch_id=439 Accuracy=89.83:  93%|█████████▎| 437/469 [00:19<00:01, 23.96it/s]\u001b[A\n",
            "Epoch=0 Loss=0.10935918986797333 Batch_id=440 Accuracy=89.84:  93%|█████████▎| 437/469 [00:19<00:01, 23.96it/s]\u001b[A\n",
            "Epoch=0 Loss=0.10935918986797333 Batch_id=440 Accuracy=89.84:  94%|█████████▍| 441/469 [00:19<00:01, 24.76it/s]\u001b[A\n",
            "Epoch=0 Loss=0.06971046328544617 Batch_id=441 Accuracy=89.86:  94%|█████████▍| 441/469 [00:19<00:01, 24.76it/s]\u001b[A\n",
            "Epoch=0 Loss=0.09956787526607513 Batch_id=442 Accuracy=89.88:  94%|█████████▍| 441/469 [00:19<00:01, 24.76it/s]\u001b[A\n",
            "Epoch=0 Loss=0.06384493410587311 Batch_id=443 Accuracy=89.89:  94%|█████████▍| 441/469 [00:19<00:01, 24.76it/s]\u001b[A\n",
            "Epoch=0 Loss=0.06384493410587311 Batch_id=443 Accuracy=89.89:  95%|█████████▍| 444/469 [00:19<00:00, 26.01it/s]\u001b[A\n",
            "Epoch=0 Loss=0.07649792730808258 Batch_id=444 Accuracy=89.91:  95%|█████████▍| 444/469 [00:19<00:00, 26.01it/s]\u001b[A\n",
            "Epoch=0 Loss=0.052216075360774994 Batch_id=445 Accuracy=89.93:  95%|█████████▍| 444/469 [00:19<00:00, 26.01it/s]\u001b[A\n",
            "Epoch=0 Loss=0.0881924256682396 Batch_id=446 Accuracy=89.95:  95%|█████████▍| 444/469 [00:19<00:00, 26.01it/s]  \u001b[A\n",
            "Epoch=0 Loss=0.0881924256682396 Batch_id=446 Accuracy=89.95:  95%|█████████▌| 447/469 [00:19<00:00, 26.87it/s]\u001b[A\n",
            "Epoch=0 Loss=0.07775850594043732 Batch_id=447 Accuracy=89.97:  95%|█████████▌| 447/469 [00:19<00:00, 26.87it/s]\u001b[A\n",
            "Epoch=0 Loss=0.050750523805618286 Batch_id=448 Accuracy=89.99:  95%|█████████▌| 447/469 [00:19<00:00, 26.87it/s]\u001b[A\n",
            "Epoch=0 Loss=0.0987417995929718 Batch_id=449 Accuracy=90.01:  95%|█████████▌| 447/469 [00:19<00:00, 26.87it/s]  \u001b[A\n",
            "Epoch=0 Loss=0.0987417995929718 Batch_id=449 Accuracy=90.01:  96%|█████████▌| 450/469 [00:19<00:00, 23.33it/s]\u001b[A\n",
            "Epoch=0 Loss=0.12328894436359406 Batch_id=450 Accuracy=90.02:  96%|█████████▌| 450/469 [00:19<00:00, 23.33it/s]\u001b[A\n",
            "Epoch=0 Loss=0.05730513855814934 Batch_id=451 Accuracy=90.04:  96%|█████████▌| 450/469 [00:19<00:00, 23.33it/s]\u001b[A\n",
            "Epoch=0 Loss=0.08180573582649231 Batch_id=452 Accuracy=90.06:  96%|█████████▌| 450/469 [00:19<00:00, 23.33it/s]\u001b[A\n",
            "Epoch=0 Loss=0.08180573582649231 Batch_id=452 Accuracy=90.06:  97%|█████████▋| 453/469 [00:19<00:00, 22.73it/s]\u001b[A\n",
            "Epoch=0 Loss=0.09418360143899918 Batch_id=453 Accuracy=90.08:  97%|█████████▋| 453/469 [00:19<00:00, 22.73it/s]\u001b[A\n",
            "Epoch=0 Loss=0.07988341152667999 Batch_id=454 Accuracy=90.09:  97%|█████████▋| 453/469 [00:19<00:00, 22.73it/s]\u001b[A\n",
            "Epoch=0 Loss=0.0840066522359848 Batch_id=455 Accuracy=90.11:  97%|█████████▋| 453/469 [00:19<00:00, 22.73it/s] \u001b[A\n",
            "Epoch=0 Loss=0.0840066522359848 Batch_id=455 Accuracy=90.11:  97%|█████████▋| 456/469 [00:19<00:00, 23.54it/s]\u001b[A\n",
            "Epoch=0 Loss=0.06448553502559662 Batch_id=456 Accuracy=90.13:  97%|█████████▋| 456/469 [00:20<00:00, 23.54it/s]\u001b[A\n",
            "Epoch=0 Loss=0.04843909293413162 Batch_id=457 Accuracy=90.15:  97%|█████████▋| 456/469 [00:20<00:00, 23.54it/s]\u001b[A\n",
            "Epoch=0 Loss=0.05917776748538017 Batch_id=458 Accuracy=90.17:  97%|█████████▋| 456/469 [00:20<00:00, 23.54it/s]\u001b[A\n",
            "Epoch=0 Loss=0.05917776748538017 Batch_id=458 Accuracy=90.17:  98%|█████████▊| 459/469 [00:20<00:00, 22.44it/s]\u001b[A\n",
            "Epoch=0 Loss=0.12832939624786377 Batch_id=459 Accuracy=90.19:  98%|█████████▊| 459/469 [00:20<00:00, 22.44it/s]\u001b[A\n",
            "Epoch=0 Loss=0.034668657928705215 Batch_id=460 Accuracy=90.21:  98%|█████████▊| 459/469 [00:20<00:00, 22.44it/s]\u001b[A\n",
            "Epoch=0 Loss=0.14737054705619812 Batch_id=461 Accuracy=90.22:  98%|█████████▊| 459/469 [00:20<00:00, 22.44it/s] \u001b[A\n",
            "Epoch=0 Loss=0.14737054705619812 Batch_id=461 Accuracy=90.22:  99%|█████████▊| 462/469 [00:20<00:00, 22.30it/s]\u001b[A\n",
            "Epoch=0 Loss=0.12441374361515045 Batch_id=462 Accuracy=90.23:  99%|█████████▊| 462/469 [00:20<00:00, 22.30it/s]\u001b[A\n",
            "Epoch=0 Loss=0.15363481640815735 Batch_id=463 Accuracy=90.24:  99%|█████████▊| 462/469 [00:20<00:00, 22.30it/s]\u001b[A\n",
            "Epoch=0 Loss=0.09279796481132507 Batch_id=464 Accuracy=90.26:  99%|█████████▊| 462/469 [00:20<00:00, 22.30it/s]\u001b[A\n",
            "Epoch=0 Loss=0.19290859997272491 Batch_id=465 Accuracy=90.27:  99%|█████████▊| 462/469 [00:20<00:00, 22.30it/s]\u001b[A\n",
            "Epoch=0 Loss=0.19290859997272491 Batch_id=465 Accuracy=90.27:  99%|█████████▉| 466/469 [00:20<00:00, 25.24it/s]\u001b[A\n",
            "Epoch=0 Loss=0.05163579806685448 Batch_id=466 Accuracy=90.29:  99%|█████████▉| 466/469 [00:20<00:00, 25.24it/s]\u001b[A\n",
            "Epoch=0 Loss=0.05073460564017296 Batch_id=467 Accuracy=90.31:  99%|█████████▉| 466/469 [00:20<00:00, 25.24it/s]\u001b[A\n",
            "Epoch=0 Loss=0.12454236298799515 Batch_id=468 Accuracy=90.32:  99%|█████████▉| 466/469 [00:20<00:00, 25.24it/s]\u001b[A\n",
            "Epoch=0 Loss=0.12454236298799515 Batch_id=468 Accuracy=90.32: 100%|██████████| 469/469 [00:20<00:00, 22.85it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-1e804471b3d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmisclassify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmisclassify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: test() takes 3 positional arguments but 4 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-P7Oqc_01kou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irlQkAwG12mH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}